{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0c81fae-ed50-4bc4-bcb2-a943dbf863a2",
   "metadata": {},
   "source": [
    "### Project Title : Classification model for predicting MIS_Status using SBA Loans data\n",
    "#### Name : Megha Chandrasekharan Nair\n",
    "#### UTDID : mxc220113"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bec937-4c8b-4764-8eea-f4f447821fdb",
   "metadata": {},
   "source": [
    "### <span style=\"color: lightgreen;\">This notebook deals with model training. The agenda is to train two models which will classify their MIS_Status of SBA loans records as 0 or 1. 1 being the loan gets defaulted and 0 being the loan is paid in full.It includes step by step processes of data cleaning, preprocessing, encoding categorical columns, scaling the numerical columns, model training and hypertuning.</span> ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e486429-edd5-4413-bf0d-05aa3a45df97",
   "metadata": {},
   "source": [
    "#### Step 1: <span style=\"color:yellow;font-style:italic\">Import all the required libraries needed to run the model.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "045aa45d-9dfd-43c2-b459-19b5d934001f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas.api.types as ptypes\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder,RobustScaler\n",
    "from category_encoders import WOEEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.metrics import f1_score,roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from scipy.stats import loguniform\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import inspect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4050e57-f13b-416b-bd22-e7e524900a72",
   "metadata": {},
   "source": [
    "#### Step 2: <span style=\"color:yellow;font-style:italic\">Read data from the csv file named \"SBA_loans_project_1.csv\" into a variable named data_full</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7678af8e-7708-487f-853f-02d323e1e7a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Zip</th>\n",
       "      <th>Bank</th>\n",
       "      <th>BankState</th>\n",
       "      <th>NAICS</th>\n",
       "      <th>NoEmp</th>\n",
       "      <th>NewExist</th>\n",
       "      <th>CreateJob</th>\n",
       "      <th>RetainedJob</th>\n",
       "      <th>FranchiseCode</th>\n",
       "      <th>UrbanRural</th>\n",
       "      <th>RevLineCr</th>\n",
       "      <th>LowDoc</th>\n",
       "      <th>DisbursementGross</th>\n",
       "      <th>BalanceGross</th>\n",
       "      <th>GrAppv</th>\n",
       "      <th>SBA_Appv</th>\n",
       "      <th>MIS_Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>APPLETON</td>\n",
       "      <td>WI</td>\n",
       "      <td>59414</td>\n",
       "      <td>ASSOCIATED BANK NATL ASSOC</td>\n",
       "      <td>WI</td>\n",
       "      <td>321918</td>\n",
       "      <td>26</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>WEATHERFORD</td>\n",
       "      <td>TX</td>\n",
       "      <td>76086</td>\n",
       "      <td>REGIONS BANK</td>\n",
       "      <td>AL</td>\n",
       "      <td>621391</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>146200.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>146200.0</td>\n",
       "      <td>124270.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>FLORENCE</td>\n",
       "      <td>SC</td>\n",
       "      <td>29505</td>\n",
       "      <td>SUPERIOR FINANCIAL GROUP, LLC</td>\n",
       "      <td>CA</td>\n",
       "      <td>236220</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>BOSTON</td>\n",
       "      <td>MA</td>\n",
       "      <td>2124</td>\n",
       "      <td>CITIZENS BANK NATL ASSOC</td>\n",
       "      <td>RI</td>\n",
       "      <td>236115</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>73100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75000.0</td>\n",
       "      <td>37500.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>LAFAYETTE</td>\n",
       "      <td>IN</td>\n",
       "      <td>47904</td>\n",
       "      <td>THE HUNTINGTON NATIONAL BANK</td>\n",
       "      <td>OH</td>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>64000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index         City State    Zip                           Bank BankState  \\\n",
       "0      0     APPLETON    WI  59414     ASSOCIATED BANK NATL ASSOC        WI   \n",
       "1      1  WEATHERFORD    TX  76086                   REGIONS BANK        AL   \n",
       "2      2     FLORENCE    SC  29505  SUPERIOR FINANCIAL GROUP, LLC        CA   \n",
       "3      3       BOSTON    MA   2124       CITIZENS BANK NATL ASSOC        RI   \n",
       "4      4    LAFAYETTE    IN  47904   THE HUNTINGTON NATIONAL BANK        OH   \n",
       "\n",
       "    NAICS  NoEmp  NewExist  CreateJob  RetainedJob  FranchiseCode  UrbanRural  \\\n",
       "0  321918     26       1.0          0            0              1           0   \n",
       "1  621391      2       1.0          1            3              0           1   \n",
       "2  236220      3       1.0          3            3              0           1   \n",
       "3  236115      5       1.0          0            5              1           1   \n",
       "4       0     82       1.0          0            0              1           0   \n",
       "\n",
       "  RevLineCr LowDoc  DisbursementGross  BalanceGross    GrAppv  SBA_Appv  \\\n",
       "0         0      N           100000.0           0.0  100000.0   80000.0   \n",
       "1         N      N           146200.0           0.0  146200.0  124270.0   \n",
       "2         N      N            20000.0           0.0   20000.0   17000.0   \n",
       "3         N      N            73100.0           0.0   75000.0   37500.0   \n",
       "4         N      Y            80000.0           0.0   80000.0   64000.0   \n",
       "\n",
       "   MIS_Status  \n",
       "0           0  \n",
       "1           0  \n",
       "2           1  \n",
       "3           1  \n",
       "4           0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_full = pd.read_csv(\"./data/SBA_loans_project_1.csv\")\n",
    "data_full.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dacc55eb-662b-460a-bae5-c470a067b1c4",
   "metadata": {},
   "source": [
    "##### Step 3: <span style=\"color:yellow;font-style:italic\">Lets describe the data to observe the factors that might impact our model(like ranges of each column,identify skewness which might indicate outliers,need for scaling etc.) so that we can take effective steps to get the best model.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdfb8799-edb9-40b1-9030-4ed975b137ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Zip</th>\n",
       "      <th>NAICS</th>\n",
       "      <th>NoEmp</th>\n",
       "      <th>NewExist</th>\n",
       "      <th>CreateJob</th>\n",
       "      <th>RetainedJob</th>\n",
       "      <th>FranchiseCode</th>\n",
       "      <th>UrbanRural</th>\n",
       "      <th>DisbursementGross</th>\n",
       "      <th>BalanceGross</th>\n",
       "      <th>GrAppv</th>\n",
       "      <th>SBA_Appv</th>\n",
       "      <th>MIS_Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>800255.000000</td>\n",
       "      <td>800255.000000</td>\n",
       "      <td>800255.000000</td>\n",
       "      <td>800255.000000</td>\n",
       "      <td>800134.000000</td>\n",
       "      <td>800255.000000</td>\n",
       "      <td>800255.000000</td>\n",
       "      <td>800255.000000</td>\n",
       "      <td>800255.000000</td>\n",
       "      <td>8.002550e+05</td>\n",
       "      <td>800255.000000</td>\n",
       "      <td>8.002550e+05</td>\n",
       "      <td>8.002550e+05</td>\n",
       "      <td>800255.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>400127.000000</td>\n",
       "      <td>53789.689389</td>\n",
       "      <td>398523.640241</td>\n",
       "      <td>11.429704</td>\n",
       "      <td>1.280583</td>\n",
       "      <td>8.452672</td>\n",
       "      <td>10.808695</td>\n",
       "      <td>2759.730583</td>\n",
       "      <td>0.757813</td>\n",
       "      <td>2.009724e+05</td>\n",
       "      <td>3.260593</td>\n",
       "      <td>1.925229e+05</td>\n",
       "      <td>1.493414e+05</td>\n",
       "      <td>0.175169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>231013.864173</td>\n",
       "      <td>31191.480137</td>\n",
       "      <td>263292.687557</td>\n",
       "      <td>75.201079</td>\n",
       "      <td>0.451842</td>\n",
       "      <td>237.167956</td>\n",
       "      <td>237.465427</td>\n",
       "      <td>12773.618653</td>\n",
       "      <td>0.646547</td>\n",
       "      <td>2.874264e+05</td>\n",
       "      <td>1527.422092</td>\n",
       "      <td>2.829154e+05</td>\n",
       "      <td>2.279605e+05</td>\n",
       "      <td>0.380112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000e+02</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>200063.500000</td>\n",
       "      <td>27558.000000</td>\n",
       "      <td>235210.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.200000e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.500000e+04</td>\n",
       "      <td>2.125000e+04</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>400127.000000</td>\n",
       "      <td>55409.000000</td>\n",
       "      <td>445310.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000e+04</td>\n",
       "      <td>6.120000e+04</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>600190.500000</td>\n",
       "      <td>83704.000000</td>\n",
       "      <td>561730.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.372760e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.250000e+05</td>\n",
       "      <td>1.750000e+05</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>800254.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>928120.000000</td>\n",
       "      <td>9999.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>8800.000000</td>\n",
       "      <td>9500.000000</td>\n",
       "      <td>92006.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.144632e+07</td>\n",
       "      <td>996262.000000</td>\n",
       "      <td>5.472000e+06</td>\n",
       "      <td>5.472000e+06</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               index            Zip          NAICS          NoEmp  \\\n",
       "count  800255.000000  800255.000000  800255.000000  800255.000000   \n",
       "mean   400127.000000   53789.689389  398523.640241      11.429704   \n",
       "std    231013.864173   31191.480137  263292.687557      75.201079   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%    200063.500000   27558.000000  235210.000000       2.000000   \n",
       "50%    400127.000000   55409.000000  445310.000000       4.000000   \n",
       "75%    600190.500000   83704.000000  561730.000000      10.000000   \n",
       "max    800254.000000   99999.000000  928120.000000    9999.000000   \n",
       "\n",
       "            NewExist      CreateJob    RetainedJob  FranchiseCode  \\\n",
       "count  800134.000000  800255.000000  800255.000000  800255.000000   \n",
       "mean        1.280583       8.452672      10.808695    2759.730583   \n",
       "std         0.451842     237.167956     237.465427   12773.618653   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         1.000000       0.000000       0.000000       1.000000   \n",
       "50%         1.000000       0.000000       1.000000       1.000000   \n",
       "75%         2.000000       1.000000       4.000000       1.000000   \n",
       "max         2.000000    8800.000000    9500.000000   92006.000000   \n",
       "\n",
       "          UrbanRural  DisbursementGross   BalanceGross        GrAppv  \\\n",
       "count  800255.000000       8.002550e+05  800255.000000  8.002550e+05   \n",
       "mean        0.757813       2.009724e+05       3.260593  1.925229e+05   \n",
       "std         0.646547       2.874264e+05    1527.422092  2.829154e+05   \n",
       "min         0.000000       0.000000e+00       0.000000  2.000000e+02   \n",
       "25%         0.000000       4.200000e+04       0.000000  3.500000e+04   \n",
       "50%         1.000000       1.000000e+05       0.000000  9.000000e+04   \n",
       "75%         1.000000       2.372760e+05       0.000000  2.250000e+05   \n",
       "max         2.000000       1.144632e+07  996262.000000  5.472000e+06   \n",
       "\n",
       "           SBA_Appv     MIS_Status  \n",
       "count  8.002550e+05  800255.000000  \n",
       "mean   1.493414e+05       0.175169  \n",
       "std    2.279605e+05       0.380112  \n",
       "min    1.000000e+02       0.000000  \n",
       "25%    2.125000e+04       0.000000  \n",
       "50%    6.120000e+04       0.000000  \n",
       "75%    1.750000e+05       0.000000  \n",
       "max    5.472000e+06       1.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_full.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee83b29-79c7-40d4-bf1e-24a32cc0087e",
   "metadata": {},
   "source": [
    "#### Step 3: <span style=\"color:yellow;font-style:italic\">Following the data description in the attached kaggle link given in the project-starter file</span>\n",
    "<ul style=\"color:orange\">\n",
    "    <li>We fill missing values in numerical columns to 0 and \"Missing\" for the categorical columns.</li>\n",
    "    <li>We need to classify if a loan is for a Franchise or a non-franchise. A code greater than 1 indicates its a franchise</li>\n",
    "    <li>Classifying if its a new business or an existing business.</li>\n",
    "    <li>Classifying if the loan was disbursed as a revolving line of credit or not</li>\n",
    "    <li>Classifying if its a Urban or a rural business</li>\n",
    "    <li>Classifying if the loan was approved with low documentation</li>\n",
    "    <li>We classify NAICS column based on their economic sectors. The first two digits of the NAICS code stands for the sector.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82a45749-3ee3-4425-b53e-7bb2e599165c",
   "metadata": {},
   "outputs": [],
   "source": [
    "artifacts_dict = {}\n",
    "artifacts_functions = {}# creating a dictionary which will store the intermediate outputs and functions which can be\n",
    "#dumped into artifacts folder and later retreived and reused in the scoring function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4fb5fc01-60c5-4b15-bd4f-b28ecc61b53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Below function is to extract first two digits of NAICS which represents a sector. Few sectors have multiple two digit codes,which is handled below.\n",
    "def get_naics(x):\n",
    "        x = int(str(x)[:2])\n",
    "        if x == 0:\n",
    "            return \"Missing\" # No valid NAICS code interpreted as missing\n",
    "        elif 31 <= x <= 33:\n",
    "            return str(31) # Manufacturing sector\n",
    "        elif 44 <= x <= 45:\n",
    "            return str(44) # Retail trade\n",
    "        elif 48 <= x <= 49:\n",
    "            return str(48) #Transportation and warehousing\n",
    "        else:\n",
    "            return str(x) \n",
    "artifacts_functions[\"get_naics\"] = inspect.getsource(get_naics) #storing the function into artifacts dictionary\n",
    "\n",
    "#Below function is to fill missing values. 0 for numerical and Missing for categorical.\n",
    "def fillMissingValues(inputdata):\n",
    "    for col in inputdata.columns:\n",
    "        if(inputdata[col].isna().sum()>0):\n",
    "            if(ptypes.is_numeric_dtype(inputdata[col])):\n",
    "                inputdata[col].fillna(0,inplace=True)\n",
    "            else:\n",
    "                inputdata[col].fillna(\"Missing\",inplace=True)\n",
    "artifacts_functions[\"fillMissingValues\"] = inspect.getsource(fillMissingValues) #storing the function into the artifacts dict\n",
    "\n",
    "#Below function cleans the Franchisecode,RevLineCr,NewExist,UrbanRural,LowDoc and NAICS columns\n",
    "def data_clean_preprocess(inputdata):\n",
    "    #franchise if a code > 1 else not a franchise\n",
    "    inputdata[\"FranchiseCode\"] = inputdata[\"FranchiseCode\"].apply(lambda x: 0 if (x == 0 or x == 1) else 1)\n",
    "    #new business if value is 0 else existing business\n",
    "    inputdata[\"NewExist\"] = inputdata[\"NewExist\"].apply(lambda x: 0 if (x==1 or x==0) else 1)\n",
    "    #Valid values are only 'Y','N' rest are considered Missing\n",
    "    inputdata[\"RevLineCr\"] = inputdata[\"RevLineCr\"].apply(lambda x: 'Y' if (x == 'Y' or x == 1) else ('N' if (x == 'N'  or x==0) else 'Missing'))\n",
    "    #Value 1 indicates 'Urban', 2 indicates 'Rural' else missing\n",
    "    inputdata[\"UrbanRural\"] = inputdata[\"UrbanRural\"].apply(lambda x: 'Urban' if (x == 1) else ('Rural' if (x==2) else 'Missing'))\n",
    "    #Valid values are only 'Y','N' rest are considered Missing\n",
    "    inputdata[\"LowDoc\"] = inputdata[\"LowDoc\"].apply(lambda x: 'Y' if (x == 'Y' or x == 1) else ('N' if (x == 'N'  or x==0) else 'Missing'))\n",
    "    #Apply sectors to NAICS column\n",
    "    inputdata['NAICS'] = inputdata['NAICS'].apply(get_naics)\n",
    "    #Set category types to the columns. ZIP is considered category as the numbers as such doesnt hold any value.\n",
    "    inputdata[['Zip',\"NewExist\",\"FranchiseCode\",\n",
    "               \"UrbanRural\",\"RevLineCr\",\"NAICS\",\"LowDoc\"]] = inputdata[['Zip',\"NewExist\",\"FranchiseCode\",\"UrbanRural\"\n",
    "                                                                        ,\"RevLineCr\",\"NAICS\",\"LowDoc\"]].astype('category')\n",
    "    #fill missing values\n",
    "    fillMissingValues(inputdata)\n",
    "    \n",
    "artifacts_functions[\"data_clean_preprocess\"] = inspect.getsource(data_clean_preprocess) # store the function in the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87bc4464-195f-4e42-a6bc-d95c54912117",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will apply the cleaning function into the data\n",
    "data_clean_preprocess(data_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a0e067-2c69-4539-98b1-af085e019af4",
   "metadata": {},
   "source": [
    "#### Step 4: <span style=\"color:yellow;font-style:italic\">Lets generate a heatmap to understand the correlations between the numerical columns. It helps in understanding which columns are highly correlated,need to be removed,need interaction features etc.</span>\n",
    "As per the heatmap generated, we observe that CreateJob and RetainedJob are highly correlated,same with the DisbursementGross,SBA_Appv and Gr_Appv. It is ideal to have interaction features between them and if possible remove them after the interaction features are created to boost the model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5e9660f-28da-40d1-8a0f-16e10acfa686",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "numeric_columns = data_full.select_dtypes(include=['number']).columns.tolist()\n",
    "sns.heatmap(data_full[numeric_columns].corr());"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b968ca-495e-4f6a-a65d-2a496f1d0811",
   "metadata": {},
   "source": [
    "#### Step 5: <span style=\"color:yellow;font-style:italic\">Let us define the target column and split the data into training,test and validation datasets</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18d05bc0-bd7e-43a7-8408-6b79b7103df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_full\n",
    "Y = data_full['MIS_Status'] #MIS_Status is the target column\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38306bb-d289-42cb-8f7e-245a27e2095c",
   "metadata": {},
   "source": [
    "#### Step 6: <span style=\"color:yellow;font-style:italic\">Create engineered features</span>\n",
    "<ol style=\"color:orange\">\n",
    "    <li>Bank Loan Count: Number of loans that are given by a bank.High number might indicate that bank's experience in dealing with deafults.</li>\n",
    "    <li>Bank UR: The mean guaranteed approval of each bank as per the urban rural status. Can track changes in approvals for urban and rural areas.</li>\n",
    "    <li>Franchise GrAppv: The mean SBA and disbursement difference for franchise and non franchise</li>\n",
    "    <li>UrbanRuralGross:  The mean SBA and disbursement difference for Urban and Rural</li>\n",
    "    <li>NewExistGross:  The mean SBA and disbursement difference for Existing and new businesses.</li>\n",
    "    <li>RevLineCrGross:  The mean SBA and disbursement difference for Revolving Line of Credit</li>\n",
    "    <li>LowDocGross:  The mean SBA and disbursement differencefor LowDocumentation</li>\n",
    "    <li>State default rates: The mean default rates per state</li>\n",
    "    <li>Industry default rates: The mean defaults per industry</li>\n",
    "    <li>DisSbaDiff: If Disbursement is greater than the SBA_Appv coverage amount.</li>\n",
    "    <li>LoanToEmployeeRatio: Loan approved to the number of employees in the business.Might indicate the size of the business.</li>\n",
    "    <li>Bank_BankState: To check performance of banks in their state vs others</li>\n",
    "    <li>SBA_Risk: The percentage of approved amount covered by SBA </li>\n",
    "    <li>ProportionSBA: Proportion of SBA Coverage</li>\n",
    "    <li>DisGrossDiff: If Disbursement is greater than the GrAppv coverage amount.</li>\n",
    "    <li>CreateRetain : Ratio of jobs created to retained.</li>\n",
    "    <li>City_State: Equivalent to interaction term City*State.Indicating performance of a city within state.</li>\n",
    "    <li>CreateNoEmp: Ratio of number of jobs created to the size of the firm.</li>\n",
    "    <li>Interaction features: Total of 6 Interaction features are created between categorical variables RevLineCr,LowDoc,UrbanRural and NewExist</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2244fc49-82e9-4c9a-a70b-f494fad0fe88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The below values are taken only from the training data and hence has to stored in the artifacts dictionary\n",
    "#as they have to be resused for mapping in the scoring\n",
    "artifacts_dict['bank_loan_counts'] = X_train['Bank'].value_counts().to_dict()\n",
    "X_train[\"DisSbaDiff\"] = (X_train[\"DisbursementGross\"] > X_train[\"SBA_Appv\"]).astype(int)\n",
    "artifacts_dict['bankperformance_ur'] = X_train.groupby(['Bank','UrbanRural'])['DisSbaDiff'].mean().to_dict()\n",
    "artifacts_dict['franchise_GrAppv'] = X_train.groupby('FranchiseCode')['DisSbaDiff'].mean().to_dict()\n",
    "artifacts_dict['urbanRuralGross'] = X_train.groupby('UrbanRural')['DisSbaDiff'].mean().to_dict()\n",
    "artifacts_dict['NewExistGross'] = X_train.groupby('NewExist')['DisSbaDiff'].mean().to_dict()\n",
    "artifacts_dict['RevLineCrGross'] = X_train.groupby('RevLineCr')['DisSbaDiff'].mean().to_dict()\n",
    "artifacts_dict['LowDocGross'] = X_train.groupby('LowDoc')['DisSbaDiff'].mean().to_dict()\n",
    "X_train[\"Bank_UR\"] = X_train.apply(lambda row: artifacts_dict[\"bankperformance_ur\"].get((row['Bank'], row['UrbanRural']), 0), axis=1)\n",
    "artifacts_dict['BankURMean'] = X_train[\"Bank_UR\"].mean()\n",
    "artifacts_dict['state_default_rates'] = X_train.groupby('State')['MIS_Status'].apply(lambda x: (x == 1).mean()).to_dict()\n",
    "artifacts_dict['industry_default_rates'] = X_train.groupby('NAICS')['MIS_Status'].apply(lambda x: (x == 1).mean()).to_dict()\n",
    "\n",
    "#a function that will create all the above listed interaction features for any input dataframe.\n",
    "def create_engineered_features(inputdata,artifacts_dict):\n",
    "    inputdata[\"DisSbaDiff\"] = (inputdata[\"DisbursementGross\"] > inputdata[\"SBA_Appv\"]).astype(int)\n",
    "    inputdata[\"Bank_UR\"] = inputdata.apply(lambda row: artifacts_dict[\"bankperformance_ur\"].get((row['Bank'], row['UrbanRural']), 0), axis=1)\n",
    "    inputdata[\"Bank_UR\"].fillna(artifacts_dict[\"BankURMean\"],inplace=True)\n",
    "    inputdata['StateDefaultRate'] = inputdata['State'].map(artifacts_dict[\"state_default_rates\"])\n",
    "    inputdata['IndustryDefaultRate'] = inputdata['NAICS'].map(artifacts_dict[\"industry_default_rates\"])\n",
    "    inputdata['LoanToEmployeeRatio'] = inputdata['GrAppv'] / (inputdata['NoEmp']+1)\n",
    "    inputdata['BankLoanCount'] = inputdata['Bank'].map(artifacts_dict[\"bank_loan_counts\"]).fillna(0)\n",
    "    inputdata[\"Bank_BankState\"] = (inputdata[\"Bank\"]==inputdata[\"BankState\"]).astype(int)\n",
    "    inputdata[\"SBA_Risk\"] = inputdata[\"SBA_Appv\"] / (inputdata[\"GrAppv\"]+1)\n",
    "    inputdata['franchise_GrAppv'] = inputdata['FranchiseCode'].apply(lambda x:artifacts_dict[\"franchise_GrAppv\"][x])\n",
    "    inputdata['urbanRuralGross'] = inputdata['UrbanRural'].apply(lambda x:artifacts_dict[\"urbanRuralGross\"][x])\n",
    "    inputdata['NewExistGross'] = inputdata['NewExist'].map(artifacts_dict[\"NewExistGross\"])\n",
    "    inputdata['RevLineCrGross'] = inputdata['RevLineCr'].apply(lambda x:artifacts_dict[\"RevLineCrGross\"][x])\n",
    "    inputdata['LowDocGross'] = inputdata['LowDoc'].apply(lambda x:artifacts_dict[\"LowDocGross\"][x])\n",
    "    inputdata[\"ProportionSBA\"] = (inputdata[\"GrAppv\"] - inputdata[\"SBA_Appv\"])/(inputdata[\"GrAppv\"]+1)\n",
    "    inputdata[\"DisGrossDiff\"] = (inputdata[\"DisbursementGross\"] > inputdata[\"GrAppv\"]).astype(int)\n",
    "    inputdata[\"CreateRetain\"] = inputdata[\"CreateJob\"]/(inputdata[\"RetainedJob\"]+1)\n",
    "    inputdata[\"City_State\"] = inputdata[\"City\"]+\"_\"+inputdata[\"State\"]\n",
    "    inputdata[\"CreateNoEmp\"] = inputdata[\"CreateJob\"]/(inputdata[\"NoEmp\"]+1)\n",
    "    inputdata[\"NewExist_RevLineCr\"] = inputdata[\"NewExist\"].astype(str)+\"_\"+inputdata[\"RevLineCr\"].astype(str)\n",
    "    inputdata[\"UrbanRural_RevLineCr\"] = inputdata[\"UrbanRural\"].astype(str)+\"_\"+inputdata[\"RevLineCr\"].astype(str)\n",
    "    inputdata[\"LowDoc_RevLineCr\"] = inputdata[\"LowDoc\"].astype(str)+\"_\"+inputdata[\"RevLineCr\"].astype(str)\n",
    "    inputdata[\"LowDoc_NewExist\"] = inputdata[\"LowDoc\"].astype(str)+\"_\"+inputdata[\"NewExist\"].astype(str)\n",
    "    inputdata[\"UrbanRural_LowDoc\"] = inputdata[\"UrbanRural\"].astype(str)+\"_\"+inputdata[\"LowDoc\"].astype(str)\n",
    "    inputdata[\"UrbanRural_NewExist\"] = inputdata[\"UrbanRural\"].astype(str)+\"_\"+inputdata[\"NewExist\"].astype(str)\n",
    "    #mapping mean values based on categorical columns creates the new column as a categorical datatype.Hence converting to numeric.\n",
    "    inputdata['franchise_GrAppv'] = pd.to_numeric(inputdata['franchise_GrAppv'], errors='coerce')\n",
    "    inputdata['NewExistGross'] = pd.to_numeric(inputdata['NewExistGross'],errors='coerce')\n",
    "    inputdata['LowDocGross'] = pd.to_numeric(inputdata['LowDocGross'],errors='coerce')\n",
    "    inputdata['RevLineCrGross'] = pd.to_numeric(inputdata['RevLineCrGross'],errors='coerce')\n",
    "    inputdata['urbanRuralGross'] = pd.to_numeric(inputdata['urbanRuralGross'],errors='coerce')\n",
    "    inputdata['IndustryDefaultRate'] = pd.to_numeric(inputdata['IndustryDefaultRate'],errors='coerce')\n",
    "    inputdata['Bank_UR'] = pd.to_numeric(inputdata['Bank_UR'],errors='coerce')\n",
    "    #Once features are created,filling missing values.\n",
    "    fillMissingValues(inputdata)\n",
    "artifacts_functions[\"create_engineered_features\"] = inspect.getsource(create_engineered_features) #store the function into the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba1b17bb-8608-44ad-9ba7-7c97188c4c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pass all the dataframes for creating the required engineered features\n",
    "create_engineered_features(X_train,artifacts_dict)\n",
    "create_engineered_features(X_val,artifacts_dict)\n",
    "create_engineered_features(X_test,artifacts_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c525747-8229-4616-960b-f69c2f66ecae",
   "metadata": {},
   "source": [
    "#### Step 7: <span style=\"color:yellow\"> We will use the same set of features for the H2O model, so lets load the cleaned and preprocessed data into h2oframe before we move ahead with Scikit encoding and scaling</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae11ae22-4b5d-4c6b-a89d-84685dab633a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321. connected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "\n",
       "#h2o-table-1.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-1 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-1 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-1 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-1 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-1 .h2o-table th,\n",
       "#h2o-table-1 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-1 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-1\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption></caption>\n",
       "    <thead></thead>\n",
       "    <tbody><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>1 hour 29 mins</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>America/Chicago</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.46.0.2</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>1 month and 22 days</td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>H2O_from_python_megha_1safhc</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>7.915 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://localhost:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.10.11 final</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n"
      ],
      "text/plain": [
       "--------------------------  -----------------------------\n",
       "H2O_cluster_uptime:         1 hour 29 mins\n",
       "H2O_cluster_timezone:       America/Chicago\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.46.0.2\n",
       "H2O_cluster_version_age:    1 month and 22 days\n",
       "H2O_cluster_name:           H2O_from_python_megha_1safhc\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    7.915 Gb\n",
       "H2O_cluster_total_cores:    8\n",
       "H2O_cluster_allowed_cores:  8\n",
       "H2O_cluster_status:         locked, healthy\n",
       "H2O_connection_url:         http://localhost:54321\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "Python_version:             3.10.11 final\n",
       "--------------------------  -----------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n"
     ]
    }
   ],
   "source": [
    "#H2O initialization\n",
    "import h2o\n",
    "h2o.init(max_mem_size = \"8G\",nthreads=8)            \n",
    "h2o.remove_all()  \n",
    "#loading data into h2oframes\n",
    "h2o_train = h2o.H2OFrame(X_train)\n",
    "h2o_val = h2o.H2OFrame(X_val)\n",
    "h2o_test = h2o.H2OFrame(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1e2b17-2466-4f19-b4ef-1c1aef6fe4b0",
   "metadata": {},
   "source": [
    "#### Step 8: <span style=\"color:yellow\">This step encodes all categorical columns into numerical using onehot encoding and WOE encoder. The columns with less than 11 values use one hot encoding and others use WOE. The encoders are fit in the training data and any other data is transformed separately based on the fit. The fitted encoders are save in the artifacts for reusability. I have used WOE instead of target as WOE is best suited for logistic regression-binary classification problems, especially in credit scoring and risk modeling.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38989db7-c78e-4eba-8ff7-0f70b504fa27",
   "metadata": {},
   "outputs": [],
   "source": [
    "artifacts_dict[\"categorical_encoders\"] = {}\n",
    "artifacts_dict[\"CategoricalColumns\"] = []\n",
    "artifacts_dict[\"numColumns\"] = []\n",
    "for col in X_train.columns:\n",
    "    if(ptypes.is_numeric_dtype(X_train[col])):\n",
    "        continue; # if a column is numeric skip\n",
    "    elif(X_train[col].nunique() <=10): # if number of unique values are less than or equal to 10, do one hot encoding\n",
    "        artifacts_dict[\"CategoricalColumns\"].append(col)\n",
    "        oh_encoder = OneHotEncoder(handle_unknown='ignore',sparse_output = False)\n",
    "        artifacts_dict[\"categorical_encoders\"][col] = oh_encoder\n",
    "        one_hot_encoded =  artifacts_dict[\"categorical_encoders\"][col].fit_transform(X_train[[col]]) # fit transform training data\n",
    "        one_hot_encoded_df = pd.DataFrame(one_hot_encoded, columns= artifacts_dict[\"categorical_encoders\"][col]\n",
    "                                          .get_feature_names_out([col]),index=X_train.index)\n",
    "        X_train = X_train.join(one_hot_encoded_df)\n",
    "        X_train=X_train.drop(columns=[col]) # drop the encoded column\n",
    "        \n",
    "        one_hot_encoded_val =  artifacts_dict[\"categorical_encoders\"][col].transform(X_val[[col]]) #transform validation data\n",
    "        one_hot_encoded_df_val = pd.DataFrame(one_hot_encoded_val, columns= artifacts_dict[\"categorical_encoders\"][col]\n",
    "                                              .get_feature_names_out([col]),index=X_val.index)\n",
    "        X_val = X_val.join(one_hot_encoded_df_val)\n",
    "        X_val=X_val.drop(columns=[col])# drop the encoded column\n",
    "\n",
    "        one_hot_encoded_test =  artifacts_dict[\"categorical_encoders\"][col].transform(X_test[[col]]) #transform test data\n",
    "        one_hot_encoded_df_test = pd.DataFrame(one_hot_encoded_test, columns= artifacts_dict[\"categorical_encoders\"][col].get_feature_names_out([col]),index=X_test.index)\n",
    "        X_test = X_test.join(one_hot_encoded_df_test)\n",
    "        X_test = X_test.drop(columns=[col])# drop the encoded column\n",
    "    else: # else use WOE\n",
    "        artifacts_dict[\"CategoricalColumns\"].append(col)\n",
    "        woe_encoder = WOEEncoder(cols=[col])\n",
    "        artifacts_dict[\"categorical_encoders\"][col] = woe_encoder.fit(X_train[col], y_train) #fit targetencoder to training data & storing it to python dict\n",
    "        X_train[col+\"_woe\"]= artifacts_dict[\"categorical_encoders\"][col].transform(X_train[col]) #train data transforming\n",
    "        X_train = X_train.drop(columns=[col])\n",
    "    \n",
    "        X_val[col+\"_woe\"]= artifacts_dict[\"categorical_encoders\"][col].transform(X_val[col]) #val data transforming\n",
    "        X_val = X_val.drop(columns=[col])\n",
    "\n",
    "        X_test[col+\"_woe\"]= artifacts_dict[\"categorical_encoders\"][col].transform(X_test[col]) #test data transforming\n",
    "        X_test = X_test.drop(columns=[col])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4cc9d8-b6a0-4a99-b7db-c1045c098c8e",
   "metadata": {},
   "source": [
    "#### Step 8: <span style=\"color:yellow\">This step involves scaling the numerical columns of our dataset. Upon examining the data, we observed that the columns are in different ranges, with some being highly skewed and likely containing outliers. To address these issues, it is ideal to standardize the data to reduce skewness and minimize the negative impact of outliers.For this purpose, I used the RobustScaler, which is particularly effective when dealing with data that contains outliers.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "783edc58-e0c3-4fbd-9f7c-0a2b03ec8251",
   "metadata": {},
   "outputs": [],
   "source": [
    "artifacts_dict[\"numColumns\"] = X_train.select_dtypes(include=['number']).columns.tolist()\n",
    "scaler = RobustScaler()\n",
    "artifacts_dict[\"Scaler\"] = scaler.fit(X_train[artifacts_dict[\"numColumns\"]]) #fitting the sacler into training data and storing it in artifactsdict\n",
    "X_trainScaled = artifacts_dict[\"Scaler\"].transform(X_train[artifacts_dict[\"numColumns\"]]) # transforming training data\n",
    "X_valScaled = artifacts_dict[\"Scaler\"].transform(X_val[artifacts_dict[\"numColumns\"]])# transforming validation data\n",
    "X_testScaled = artifacts_dict[\"Scaler\"].transform(X_test[artifacts_dict[\"numColumns\"]])# transforming test data\n",
    "# replacing actual columns with scaled columns\n",
    "X_train[artifacts_dict[\"numColumns\"]] = X_trainScaled \n",
    "X_val[artifacts_dict[\"numColumns\"]] = X_valScaled\n",
    "X_test[artifacts_dict[\"numColumns\"]] = X_testScaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a0c05f-8684-4bc9-93dc-fa26ac77d633",
   "metadata": {},
   "source": [
    "#### Step 9: <span style=\"color:yellow\">Data preview and dropping unwanted columns. I have removed index,target column(MIS_Status) and one of the one hot encoded columns of each category to avoid multicollinearity. The base case is 'NewExist_1','FranchiseCode_1','UrbanRural_Rural','RevLineCr_N','LowDoc_N'</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c66b834f-57ee-4f28-9cb5-05a7270c560d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NoEmp</th>\n",
       "      <th>CreateJob</th>\n",
       "      <th>RetainedJob</th>\n",
       "      <th>DisbursementGross</th>\n",
       "      <th>BalanceGross</th>\n",
       "      <th>GrAppv</th>\n",
       "      <th>SBA_Appv</th>\n",
       "      <th>DisSbaDiff</th>\n",
       "      <th>Bank_UR</th>\n",
       "      <th>StateDefaultRate</th>\n",
       "      <th>IndustryDefaultRate</th>\n",
       "      <th>LoanToEmployeeRatio</th>\n",
       "      <th>BankLoanCount</th>\n",
       "      <th>Bank_BankState</th>\n",
       "      <th>SBA_Risk</th>\n",
       "      <th>franchise_GrAppv</th>\n",
       "      <th>urbanRuralGross</th>\n",
       "      <th>NewExistGross</th>\n",
       "      <th>RevLineCrGross</th>\n",
       "      <th>LowDocGross</th>\n",
       "      <th>ProportionSBA</th>\n",
       "      <th>DisGrossDiff</th>\n",
       "      <th>CreateRetain</th>\n",
       "      <th>CreateNoEmp</th>\n",
       "      <th>City_woe</th>\n",
       "      <th>State_woe</th>\n",
       "      <th>Zip_woe</th>\n",
       "      <th>Bank_woe</th>\n",
       "      <th>BankState_woe</th>\n",
       "      <th>NAICS_woe</th>\n",
       "      <th>NewExist_0</th>\n",
       "      <th>FranchiseCode_0</th>\n",
       "      <th>UrbanRural_Missing</th>\n",
       "      <th>UrbanRural_Urban</th>\n",
       "      <th>RevLineCr_Missing</th>\n",
       "      <th>RevLineCr_Y</th>\n",
       "      <th>LowDoc_Missing</th>\n",
       "      <th>LowDoc_Y</th>\n",
       "      <th>City_State_woe</th>\n",
       "      <th>NewExist_RevLineCr_0_Missing</th>\n",
       "      <th>NewExist_RevLineCr_0_N</th>\n",
       "      <th>NewExist_RevLineCr_0_Y</th>\n",
       "      <th>NewExist_RevLineCr_1_Missing</th>\n",
       "      <th>NewExist_RevLineCr_1_N</th>\n",
       "      <th>NewExist_RevLineCr_1_Y</th>\n",
       "      <th>UrbanRural_RevLineCr_Missing_Missing</th>\n",
       "      <th>UrbanRural_RevLineCr_Missing_N</th>\n",
       "      <th>UrbanRural_RevLineCr_Missing_Y</th>\n",
       "      <th>UrbanRural_RevLineCr_Rural_Missing</th>\n",
       "      <th>UrbanRural_RevLineCr_Rural_N</th>\n",
       "      <th>UrbanRural_RevLineCr_Rural_Y</th>\n",
       "      <th>UrbanRural_RevLineCr_Urban_Missing</th>\n",
       "      <th>UrbanRural_RevLineCr_Urban_N</th>\n",
       "      <th>UrbanRural_RevLineCr_Urban_Y</th>\n",
       "      <th>LowDoc_RevLineCr_Missing_Missing</th>\n",
       "      <th>LowDoc_RevLineCr_Missing_N</th>\n",
       "      <th>LowDoc_RevLineCr_Missing_Y</th>\n",
       "      <th>LowDoc_RevLineCr_N_Missing</th>\n",
       "      <th>LowDoc_RevLineCr_N_N</th>\n",
       "      <th>LowDoc_RevLineCr_N_Y</th>\n",
       "      <th>LowDoc_RevLineCr_Y_Missing</th>\n",
       "      <th>LowDoc_RevLineCr_Y_N</th>\n",
       "      <th>LowDoc_RevLineCr_Y_Y</th>\n",
       "      <th>LowDoc_NewExist_Missing_0</th>\n",
       "      <th>LowDoc_NewExist_Missing_1</th>\n",
       "      <th>LowDoc_NewExist_N_0</th>\n",
       "      <th>LowDoc_NewExist_N_1</th>\n",
       "      <th>LowDoc_NewExist_Y_0</th>\n",
       "      <th>LowDoc_NewExist_Y_1</th>\n",
       "      <th>UrbanRural_LowDoc_Missing_Missing</th>\n",
       "      <th>UrbanRural_LowDoc_Missing_N</th>\n",
       "      <th>UrbanRural_LowDoc_Missing_Y</th>\n",
       "      <th>UrbanRural_LowDoc_Rural_Missing</th>\n",
       "      <th>UrbanRural_LowDoc_Rural_N</th>\n",
       "      <th>UrbanRural_LowDoc_Rural_Y</th>\n",
       "      <th>UrbanRural_LowDoc_Urban_Missing</th>\n",
       "      <th>UrbanRural_LowDoc_Urban_N</th>\n",
       "      <th>UrbanRural_LowDoc_Urban_Y</th>\n",
       "      <th>UrbanRural_NewExist_Missing_0</th>\n",
       "      <th>UrbanRural_NewExist_Missing_1</th>\n",
       "      <th>UrbanRural_NewExist_Rural_0</th>\n",
       "      <th>UrbanRural_NewExist_Rural_1</th>\n",
       "      <th>UrbanRural_NewExist_Urban_0</th>\n",
       "      <th>UrbanRural_NewExist_Urban_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>156364</th>\n",
       "      <td>-0.375</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.438144</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.394737</td>\n",
       "      <td>-0.316278</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.622120</td>\n",
       "      <td>1.072650</td>\n",
       "      <td>0.252152</td>\n",
       "      <td>-0.245614</td>\n",
       "      <td>0.474272</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.285561</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.857552e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.5</td>\n",
       "      <td>23.333333</td>\n",
       "      <td>0.954802</td>\n",
       "      <td>0.918167</td>\n",
       "      <td>0.992721</td>\n",
       "      <td>1.676438</td>\n",
       "      <td>0.450159</td>\n",
       "      <td>0.199419</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.830898</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738650</th>\n",
       "      <td>-0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>-0.385052</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.340526</td>\n",
       "      <td>-0.316931</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.128091</td>\n",
       "      <td>-1.613098</td>\n",
       "      <td>0.304680</td>\n",
       "      <td>-0.295088</td>\n",
       "      <td>0.067707</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.714341</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.49325</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.142698e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016877</td>\n",
       "      <td>-1.910907</td>\n",
       "      <td>0.558551</td>\n",
       "      <td>-0.310987</td>\n",
       "      <td>0.728026</td>\n",
       "      <td>0.238474</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268548</th>\n",
       "      <td>1.750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.051546</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.070661</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.894950</td>\n",
       "      <td>0.071552</td>\n",
       "      <td>0.095815</td>\n",
       "      <td>-0.361958</td>\n",
       "      <td>-0.185465</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.142839</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.428682e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.114378</td>\n",
       "      <td>0.067270</td>\n",
       "      <td>3.681698</td>\n",
       "      <td>-0.404491</td>\n",
       "      <td>-0.323878</td>\n",
       "      <td>0.078748</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.024355</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313434</th>\n",
       "      <td>-0.250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.515464</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.580049</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.916361</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.252152</td>\n",
       "      <td>2.245614</td>\n",
       "      <td>-0.170995</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-7.703420e-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.696605</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.471812</td>\n",
       "      <td>-0.953672</td>\n",
       "      <td>0.450159</td>\n",
       "      <td>0.199419</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.628670</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350466</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.322165</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.276316</td>\n",
       "      <td>-0.188193</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.220674</td>\n",
       "      <td>0.071552</td>\n",
       "      <td>-0.901708</td>\n",
       "      <td>-0.245614</td>\n",
       "      <td>1.646725</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.322838</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.229199e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.172927</td>\n",
       "      <td>0.067270</td>\n",
       "      <td>-0.223583</td>\n",
       "      <td>-0.062246</td>\n",
       "      <td>0.097722</td>\n",
       "      <td>-1.043003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.167242</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        NoEmp  CreateJob  RetainedJob  DisbursementGross  BalanceGross  \\\n",
       "156364 -0.375       10.0        -0.25          -0.438144           0.0   \n",
       "738650 -0.125        0.0         0.50          -0.385052           0.0   \n",
       "268548  1.750        0.0        -0.25          -0.051546           0.0   \n",
       "313434 -0.250        0.0         0.25           0.515464           0.0   \n",
       "350466  0.000        0.0        -0.25          -0.322165           0.0   \n",
       "\n",
       "          GrAppv  SBA_Appv  DisSbaDiff   Bank_UR  StateDefaultRate  \\\n",
       "156364 -0.394737 -0.316278         0.0  0.622120          1.072650   \n",
       "738650 -0.340526 -0.316931         0.0 -0.128091         -1.613098   \n",
       "268548  0.000000  0.070661         0.0 -0.894950          0.071552   \n",
       "313434  0.578947  0.580049         0.0 -0.916361          0.000000   \n",
       "350466 -0.276316 -0.188193         0.0 -0.220674          0.071552   \n",
       "\n",
       "        IndustryDefaultRate  LoanToEmployeeRatio  BankLoanCount  \\\n",
       "156364             0.252152            -0.245614       0.474272   \n",
       "738650             0.304680            -0.295088       0.067707   \n",
       "268548             0.095815            -0.361958      -0.185465   \n",
       "313434             0.252152             2.245614      -0.170995   \n",
       "350466            -0.901708            -0.245614       1.646725   \n",
       "\n",
       "        Bank_BankState  SBA_Risk  franchise_GrAppv  urbanRuralGross  \\\n",
       "156364             0.0  0.285561               0.0          0.00000   \n",
       "738650             0.0 -0.714341               0.0         -0.49325   \n",
       "268548             0.0  0.142839               0.0         -1.00000   \n",
       "313434             0.0 -0.000005               0.0          0.00000   \n",
       "350466             0.0  0.322838               0.0         -1.00000   \n",
       "\n",
       "        NewExistGross  RevLineCrGross  LowDocGross  ProportionSBA  \\\n",
       "156364            0.0            -1.0          0.0  -2.857552e-01   \n",
       "738650            1.0            -1.0          0.0   7.142698e-01   \n",
       "268548            0.0            -1.0          0.0  -1.428682e-01   \n",
       "313434            0.0             0.0          0.0  -7.703420e-07   \n",
       "350466            0.0            -1.0          0.0  -3.229199e-01   \n",
       "\n",
       "        DisGrossDiff  CreateRetain  CreateNoEmp  City_woe  State_woe  \\\n",
       "156364           0.0          42.5    23.333333  0.954802   0.918167   \n",
       "738650           0.0           0.0     0.000000  0.016877  -1.910907   \n",
       "268548           0.0           0.0     0.000000  1.114378   0.067270   \n",
       "313434           0.0           0.0     0.000000 -0.696605   0.000000   \n",
       "350466           0.0           0.0     0.000000 -0.172927   0.067270   \n",
       "\n",
       "         Zip_woe  Bank_woe  BankState_woe  NAICS_woe  NewExist_0  \\\n",
       "156364  0.992721  1.676438       0.450159   0.199419         0.0   \n",
       "738650  0.558551 -0.310987       0.728026   0.238474        -1.0   \n",
       "268548  3.681698 -0.404491      -0.323878   0.078748         0.0   \n",
       "313434 -0.471812 -0.953672       0.450159   0.199419         0.0   \n",
       "350466 -0.223583 -0.062246       0.097722  -1.043003         0.0   \n",
       "\n",
       "        FranchiseCode_0  UrbanRural_Missing  UrbanRural_Urban  \\\n",
       "156364              0.0                 0.0               0.0   \n",
       "738650              0.0                 0.0              -1.0   \n",
       "268548              0.0                 1.0              -1.0   \n",
       "313434              0.0                 0.0               0.0   \n",
       "350466              0.0                 1.0              -1.0   \n",
       "\n",
       "        RevLineCr_Missing  RevLineCr_Y  LowDoc_Missing  LowDoc_Y  \\\n",
       "156364                0.0          0.0             0.0       0.0   \n",
       "738650                0.0          0.0             0.0       0.0   \n",
       "268548                0.0          0.0             0.0       0.0   \n",
       "313434                1.0          0.0             0.0       0.0   \n",
       "350466                0.0          0.0             0.0       0.0   \n",
       "\n",
       "        City_State_woe  NewExist_RevLineCr_0_Missing  NewExist_RevLineCr_0_N  \\\n",
       "156364        0.830898                           0.0                     1.0   \n",
       "738650        0.000000                           0.0                     0.0   \n",
       "268548        1.024355                           0.0                     1.0   \n",
       "313434       -0.628670                           1.0                     0.0   \n",
       "350466       -0.167242                           0.0                     1.0   \n",
       "\n",
       "        NewExist_RevLineCr_0_Y  NewExist_RevLineCr_1_Missing  \\\n",
       "156364                     0.0                           0.0   \n",
       "738650                     0.0                           0.0   \n",
       "268548                     0.0                           0.0   \n",
       "313434                     0.0                           0.0   \n",
       "350466                     0.0                           0.0   \n",
       "\n",
       "        NewExist_RevLineCr_1_N  NewExist_RevLineCr_1_Y  \\\n",
       "156364                     0.0                     0.0   \n",
       "738650                     1.0                     0.0   \n",
       "268548                     0.0                     0.0   \n",
       "313434                     0.0                     0.0   \n",
       "350466                     0.0                     0.0   \n",
       "\n",
       "        UrbanRural_RevLineCr_Missing_Missing  UrbanRural_RevLineCr_Missing_N  \\\n",
       "156364                                   0.0                             0.0   \n",
       "738650                                   0.0                             0.0   \n",
       "268548                                   0.0                             1.0   \n",
       "313434                                   0.0                             0.0   \n",
       "350466                                   0.0                             1.0   \n",
       "\n",
       "        UrbanRural_RevLineCr_Missing_Y  UrbanRural_RevLineCr_Rural_Missing  \\\n",
       "156364                             0.0                                 0.0   \n",
       "738650                             0.0                                 0.0   \n",
       "268548                             0.0                                 0.0   \n",
       "313434                             0.0                                 0.0   \n",
       "350466                             0.0                                 0.0   \n",
       "\n",
       "        UrbanRural_RevLineCr_Rural_N  UrbanRural_RevLineCr_Rural_Y  \\\n",
       "156364                           0.0                           0.0   \n",
       "738650                           1.0                           0.0   \n",
       "268548                           0.0                           0.0   \n",
       "313434                           0.0                           0.0   \n",
       "350466                           0.0                           0.0   \n",
       "\n",
       "        UrbanRural_RevLineCr_Urban_Missing  UrbanRural_RevLineCr_Urban_N  \\\n",
       "156364                                 0.0                           1.0   \n",
       "738650                                 0.0                           0.0   \n",
       "268548                                 0.0                           0.0   \n",
       "313434                                 1.0                           0.0   \n",
       "350466                                 0.0                           0.0   \n",
       "\n",
       "        UrbanRural_RevLineCr_Urban_Y  LowDoc_RevLineCr_Missing_Missing  \\\n",
       "156364                           0.0                               0.0   \n",
       "738650                           0.0                               0.0   \n",
       "268548                           0.0                               0.0   \n",
       "313434                           0.0                               0.0   \n",
       "350466                           0.0                               0.0   \n",
       "\n",
       "        LowDoc_RevLineCr_Missing_N  LowDoc_RevLineCr_Missing_Y  \\\n",
       "156364                         0.0                         0.0   \n",
       "738650                         0.0                         0.0   \n",
       "268548                         0.0                         0.0   \n",
       "313434                         0.0                         0.0   \n",
       "350466                         0.0                         0.0   \n",
       "\n",
       "        LowDoc_RevLineCr_N_Missing  LowDoc_RevLineCr_N_N  \\\n",
       "156364                         0.0                   1.0   \n",
       "738650                         0.0                   1.0   \n",
       "268548                         0.0                   1.0   \n",
       "313434                         1.0                   0.0   \n",
       "350466                         0.0                   1.0   \n",
       "\n",
       "        LowDoc_RevLineCr_N_Y  LowDoc_RevLineCr_Y_Missing  \\\n",
       "156364                   0.0                         0.0   \n",
       "738650                   0.0                         0.0   \n",
       "268548                   0.0                         0.0   \n",
       "313434                   0.0                         0.0   \n",
       "350466                   0.0                         0.0   \n",
       "\n",
       "        LowDoc_RevLineCr_Y_N  LowDoc_RevLineCr_Y_Y  LowDoc_NewExist_Missing_0  \\\n",
       "156364                   0.0                   0.0                        0.0   \n",
       "738650                   0.0                   0.0                        0.0   \n",
       "268548                   0.0                   0.0                        0.0   \n",
       "313434                   0.0                   0.0                        0.0   \n",
       "350466                   0.0                   0.0                        0.0   \n",
       "\n",
       "        LowDoc_NewExist_Missing_1  LowDoc_NewExist_N_0  LowDoc_NewExist_N_1  \\\n",
       "156364                        0.0                  0.0                  0.0   \n",
       "738650                        0.0                 -1.0                  1.0   \n",
       "268548                        0.0                  0.0                  0.0   \n",
       "313434                        0.0                  0.0                  0.0   \n",
       "350466                        0.0                  0.0                  0.0   \n",
       "\n",
       "        LowDoc_NewExist_Y_0  LowDoc_NewExist_Y_1  \\\n",
       "156364                  0.0                  0.0   \n",
       "738650                  0.0                  0.0   \n",
       "268548                  0.0                  0.0   \n",
       "313434                  0.0                  0.0   \n",
       "350466                  0.0                  0.0   \n",
       "\n",
       "        UrbanRural_LowDoc_Missing_Missing  UrbanRural_LowDoc_Missing_N  \\\n",
       "156364                                0.0                          0.0   \n",
       "738650                                0.0                          0.0   \n",
       "268548                                0.0                          1.0   \n",
       "313434                                0.0                          0.0   \n",
       "350466                                0.0                          1.0   \n",
       "\n",
       "        UrbanRural_LowDoc_Missing_Y  UrbanRural_LowDoc_Rural_Missing  \\\n",
       "156364                          0.0                              0.0   \n",
       "738650                          0.0                              0.0   \n",
       "268548                          0.0                              0.0   \n",
       "313434                          0.0                              0.0   \n",
       "350466                          0.0                              0.0   \n",
       "\n",
       "        UrbanRural_LowDoc_Rural_N  UrbanRural_LowDoc_Rural_Y  \\\n",
       "156364                        0.0                        0.0   \n",
       "738650                        1.0                        0.0   \n",
       "268548                        0.0                        0.0   \n",
       "313434                        0.0                        0.0   \n",
       "350466                        0.0                        0.0   \n",
       "\n",
       "        UrbanRural_LowDoc_Urban_Missing  UrbanRural_LowDoc_Urban_N  \\\n",
       "156364                              0.0                        1.0   \n",
       "738650                              0.0                        0.0   \n",
       "268548                              0.0                        0.0   \n",
       "313434                              0.0                        1.0   \n",
       "350466                              0.0                        0.0   \n",
       "\n",
       "        UrbanRural_LowDoc_Urban_Y  UrbanRural_NewExist_Missing_0  \\\n",
       "156364                        0.0                            0.0   \n",
       "738650                        0.0                            0.0   \n",
       "268548                        0.0                            1.0   \n",
       "313434                        0.0                            0.0   \n",
       "350466                        0.0                            1.0   \n",
       "\n",
       "        UrbanRural_NewExist_Missing_1  UrbanRural_NewExist_Rural_0  \\\n",
       "156364                            0.0                          0.0   \n",
       "738650                            0.0                          0.0   \n",
       "268548                            0.0                          0.0   \n",
       "313434                            0.0                          0.0   \n",
       "350466                            0.0                          0.0   \n",
       "\n",
       "        UrbanRural_NewExist_Rural_1  UrbanRural_NewExist_Urban_0  \\\n",
       "156364                          0.0                          1.0   \n",
       "738650                          1.0                          0.0   \n",
       "268548                          0.0                          0.0   \n",
       "313434                          0.0                          1.0   \n",
       "350466                          0.0                          0.0   \n",
       "\n",
       "        UrbanRural_NewExist_Urban_1  \n",
       "156364                          0.0  \n",
       "738650                          0.0  \n",
       "268548                          0.0  \n",
       "313434                          0.0  \n",
       "350466                          0.0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train.drop(columns = ['index','NewExist_1','FranchiseCode_1','UrbanRural_Rural','RevLineCr_N','LowDoc_N',\"MIS_Status\"])\n",
    "X_val = X_val.drop(columns = ['index','NewExist_1','FranchiseCode_1','UrbanRural_Rural','RevLineCr_N','LowDoc_N',\"MIS_Status\"])\n",
    "X_test = X_test.drop(columns = ['index','NewExist_1','FranchiseCode_1','UrbanRural_Rural','RevLineCr_N','LowDoc_N',\"MIS_Status\"])\n",
    "# Set display option to show all columns\n",
    "pd.set_option('display.max_columns', None)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c440395-7bab-4cfc-9f62-080f3ca1a1e3",
   "metadata": {},
   "source": [
    "#### Step 9 : <span style=\"color:yellow\"> With the above data a logistic regression model is trained using the training data. The trained model is then used to predict the validation set to understand its performance and necessary steps needed to hypertune further.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "08f56524-654d-4189-acec-6c1d508a97dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________Training_______________\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.72      0.81    395952\n",
      "           1       0.36      0.74      0.49     84201\n",
      "\n",
      "    accuracy                           0.72    480153\n",
      "   macro avg       0.65      0.73      0.65    480153\n",
      "weighted avg       0.83      0.72      0.75    480153\n",
      "\n",
      "_________________Validation_______________\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.71      0.80    132006\n",
      "           1       0.33      0.69      0.45     28045\n",
      "\n",
      "    accuracy                           0.70    160051\n",
      "   macro avg       0.62      0.70      0.62    160051\n",
      "weighted avg       0.81      0.70      0.74    160051\n",
      "\n",
      "AUC of training data is 0.8106527342462421\n",
      "AUC of validation data is 0.7674360386818185\n"
     ]
    }
   ],
   "source": [
    "basemodel = LogisticRegression(\n",
    "    max_iter=2000,\n",
    "    class_weight='balanced'\n",
    ")\n",
    "basemodel.fit(X_train, y_train)\n",
    "y_pred = basemodel.predict(X_train)\n",
    "y_pred_val = basemodel.predict(X_val)\n",
    "print(\"_________________Training_______________\")\n",
    "print(classification_report(y_train, y_pred))\n",
    "print(\"_________________Validation_______________\")\n",
    "print(classification_report(y_val, y_pred_val))\n",
    "y_pred_prob = basemodel.predict_proba(X_train)[:, 1]\n",
    "y_pred_prob2 = basemodel.predict_proba(X_val)[:, 1]\n",
    "roc_auc_train = roc_auc_score(y_train, y_pred_prob)\n",
    "print(\"AUC of training data is {}\".format(roc_auc_train))\n",
    "roc_auc_val = roc_auc_score(y_val, y_pred_prob2)\n",
    "print(\"AUC of validation data is {}\".format(roc_auc_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c584080-64b8-4bef-a630-6916788942f4",
   "metadata": {},
   "source": [
    "Summary of the above results.\n",
    "The model struggles more with predicting class 1 (minority class), as indicated by lower precision and varying levels of recall.\n",
    "Both in training and validation sets, there is a significant class imbalance (0 being much more frequent than 1), which affects the precision and recall for class 1.\n",
    "The slight drop in metrics from training to validation suggests some degree of overfitting, where the model may be fitting too closely to the training data characteristics.\n",
    "Higher range of AUC,indicates that the model has good discrimination ability between the classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e79507-d671-4318-a289-1a57baafdad7",
   "metadata": {},
   "source": [
    "#### Step 10: <span style=\"color:yellow\">Model Hypertuning. These are the list of parameters that are used for model tuning.</span>\n",
    "<ul style=\"color:orange\">\n",
    "    <li>Regularization strength 5 values logarithmically spaced between 10^-4 to 10^4</li>\n",
    "    <li>Types of regularizations: Lasso and ridge</li>\n",
    "    <li>Optimization algorithms:liblinear as it supports both l1 and l2 regularizations</li>\n",
    "    <li>Tolerance for Convergence:[1e-4, 1e-3, 1e-2]</li>\n",
    "    <li>Handling Class Imbalance:With None and balanced class_weight parameter</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e9066d02-5f1f-4941-bb55-d484f58b86b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found: {'C': 10000.0, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter': 3000, 'tol': 0.001, 'class_weight': None}\n",
      "Best score achieved: 0.7680600509557761\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'C': np.logspace(-4, 4, 5),  # 5 different values for regularization strength\n",
    "    'penalty': ['l1', 'l2'],  # Use only 'l1' and 'l2' penalties\n",
    "    'solver': ['liblinear'],  # Solver that support both 'l1' and 'l2' penalties\n",
    "    'max_iter': [3000],\n",
    "    'tol': [1e-4, 1e-3, 1e-2],  #Tolerance values\n",
    "    'class_weight': [None, 'balanced']  # Class weight\n",
    "}\n",
    "\n",
    "from itertools import product\n",
    "# Generate all combinations of parameters\n",
    "param_combinations = list(product(\n",
    "    param_grid['C'],\n",
    "    param_grid['penalty'],\n",
    "    param_grid['solver'],\n",
    "    param_grid['max_iter'],\n",
    "    param_grid['tol'],\n",
    "    param_grid['class_weight']\n",
    "))\n",
    "# Initialize variables to store the best parameters and best score\n",
    "best_params = None\n",
    "best_score = 0\n",
    "\n",
    "for params in param_combinations:\n",
    "    C, penalty, solver, max_iter, tol, class_weight = params\n",
    "    \n",
    "    # Instantiate the logistic regression model with the current parameters\n",
    "    model = LogisticRegression(\n",
    "        C=C,\n",
    "        penalty=penalty,\n",
    "        solver=solver,\n",
    "        max_iter=max_iter,\n",
    "        tol=tol,\n",
    "        class_weight=class_weight\n",
    "    )\n",
    "    \n",
    "    # Fit the model on the training data\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict probabilities on the validation set\n",
    "    y_val_pred_proba = model.predict_proba(X_val)[:, 1]\n",
    "    \n",
    "    # Calculate the ROC AUC score\n",
    "    score = roc_auc_score(y_val, y_val_pred_proba)\n",
    "    \n",
    "    # Update best score and parameters if the current score is better\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_params = {\n",
    "            'C': C,\n",
    "            'penalty': penalty,\n",
    "            'solver': solver,\n",
    "            'max_iter': max_iter,\n",
    "            'tol': tol,\n",
    "            'class_weight': class_weight\n",
    "        }\n",
    "\n",
    "# Output the best parameters and score\n",
    "print(f\"Best parameters found: {best_params}\")\n",
    "print(f\"Best score achieved: {best_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fce55d0-ed00-4a1a-b783-d88d3a3840a3",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li>Regularization Strength (C=10000.0):Indicates minimal regularization, allowing the model to fit the training data more closely.</li>\n",
    "    <li>l2 penalty:Ridge regularization was chosen, which helps to prevent overfitting by penalizing large coefficients but does not force coefficients         to zero.</li>\n",
    "    <li>Solver (liblinear): Efficient for small to medium-sized datasets and supports the chosen l2 penalty.</li>\n",
    "    <li>Iterations (max_iter=3000): Provides ample iterations for the model to converge to a solution.</li>\n",
    "    <li>Tolerance (tol=0.001): Specifies a relatively small threshold for convergence, ensuring precise optimization.</li>\n",
    "    <li>Class Weight: No adjustment for class imbalance was necessary, implying the dataset may have been balanced or the model performed well without weighting.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404b8328-a52f-4004-9a5f-eac411992bf6",
   "metadata": {},
   "source": [
    "#### Step 11: <span style=\"color:yellow\">Training a new model with the best parameters on the training data</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "06865668-af7f-4097-8b0c-737d33cb1ae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC of training data is 0.810640120985262\n",
      "AUC of validation data is 0.7680600509557761\n"
     ]
    }
   ],
   "source": [
    "bestmodel = LogisticRegression(\n",
    "    class_weight=None,\n",
    "    max_iter=3000,\n",
    "    penalty='l2',\n",
    "    tol=0.001,\n",
    "    C=10000.0,\n",
    "    solver='liblinear'\n",
    ")# Increase max_iter if needed\n",
    "bestmodel.fit(X_train, y_train)\n",
    "y_pred_prob = bestmodel.predict_proba(X_train)[:, 1]\n",
    "y_pred_prob2 = bestmodel.predict_proba(X_val)[:, 1]\n",
    "roc_auc_train = roc_auc_score(y_train, y_pred_prob)\n",
    "print(\"AUC of training data is {}\".format(roc_auc_train))\n",
    "roc_auc_val = roc_auc_score(y_val, y_pred_prob2)\n",
    "print(\"AUC of validation data is {}\".format(roc_auc_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06dffc9-01c1-4383-b014-3508354edfc3",
   "metadata": {},
   "source": [
    "We see a very slight increase in the AUC of validation after using a model with the best parameters. But The drop in AUC from training data to validation might be a sign of the model overfitting closely to the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b2d809-db27-47ce-837c-a144c0e38a7e",
   "metadata": {},
   "source": [
    "#### Step 12: <span style=\"color:yellow\">Finding threshold that maximizes f1 score</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "22f9391c-fda0-43f3-8e6d-842cdf3aa9dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold: 0.31\n",
      "Best F1 score: 0.694536735865593\n"
     ]
    }
   ],
   "source": [
    "# Define a range of thresholds to evaluate\n",
    "thresholds = np.arange(0.0, 1.0, 0.01)\n",
    "y_probs = bestmodel.predict_proba(X_train)\n",
    "# Initialize variables to store the best threshold and the highest F1 score\n",
    "best_threshold_scikit = 0.0\n",
    "best_f1 = 0.0\n",
    "# Loop over the thresholds and calculate F1 scores\n",
    "for threshold in thresholds:\n",
    "    y_score = (y_probs[:, 1] >= threshold).astype(int)\n",
    "    current_f1 = f1_score(y_train, y_score,average='macro')\n",
    "    if current_f1 > best_f1:\n",
    "        best_f1 = current_f1\n",
    "        best_threshold_scikit = threshold\n",
    "print(f'Best threshold: {best_threshold_scikit}')\n",
    "print(f'Best F1 score: {best_f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5a768c-833f-484d-8133-5be41c808981",
   "metadata": {},
   "source": [
    "#### Step 11: <span style=\"color:yellow\">Lets train a H2O model with the data that we had stored in Step 7. Set all the categorical columns as asfactor so that the H2O GLM handles categories by its own.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "934789f9-af67-4e73-8fb4-72835cdb545b",
   "metadata": {},
   "outputs": [],
   "source": [
    "h2o_train[artifacts_dict[\"CategoricalColumns\"]]= h2o_train[artifacts_dict[\"CategoricalColumns\"]].asfactor()\n",
    "h2o_val[artifacts_dict[\"CategoricalColumns\"]] = h2o_val[artifacts_dict[\"CategoricalColumns\"]].asfactor()\n",
    "h2o_test[artifacts_dict[\"CategoricalColumns\"]] = h2o_test[artifacts_dict[\"CategoricalColumns\"]].asfactor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5e0b64-176b-4817-ac0c-42c3ce90f6a2",
   "metadata": {},
   "source": [
    "#### Step 12: <span style=\"color:yellow\">Store the model predictor columns and the target column 'MIS_Status'</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cfea31eb-d1fc-45b6-bc2c-f9388ee78393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare predictors and response columns\n",
    "covtype_X = h2o_train.columns\n",
    "covtype_y = \"MIS_Status\" #Target columns\n",
    "covtype_X.remove(covtype_y) #Remove target column\n",
    "covtype_X.remove('index') #Remove index column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ada5b96-1925-4dec-8fd2-1ff1022d5e4c",
   "metadata": {},
   "source": [
    "#### Step 13: <span style=\"color:yellow\">Train a basic H2O GLM with default parameters</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "61a6beb9-49d1-461e-9b8e-026ff139be58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n"
     ]
    }
   ],
   "source": [
    "from h2o.estimators.glm import H2OGeneralizedLinearEstimator\n",
    "glm_binom = H2OGeneralizedLinearEstimator(\n",
    "                    model_id=\"glm_v3\",\n",
    "                    solver=\"L_BFGS\",\n",
    "                    family=\"binomial\", # classifier with binary target\n",
    "                    max_iterations = 2000,\n",
    ")\n",
    "\n",
    "glm_binom.train(x=covtype_X, y=covtype_y, training_frame=h2o_train, validation_frame=h2o_val);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bd1cd2c4-698a-4b23-bb07-6029a7b3f1ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomialGLM: glm\n",
       "** Reported on test data. **\n",
       "\n",
       "MSE: 0.12413049522770588\n",
       "RMSE: 0.3523215792819195\n",
       "LogLoss: 0.39754376074662856\n",
       "AUC: 0.7609598349213056\n",
       "AUCPR: 0.4307181079129981\n",
       "Gini: 0.5219196698426112\n",
       "Null degrees of freedom: 160050\n",
       "Residual degrees of freedom: 65807\n",
       "Null deviance: 148551.6010573488\n",
       "Residual deviance: 127254.55290251729\n",
       "AIC: 315742.55290251726</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-2.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-2 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-2 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-2 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-2 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-2 .h2o-table th,\n",
       "#h2o-table-2 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-2 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-2\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.25960656340740557</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>0</th>\n",
       "<th>1</th>\n",
       "<th>Error</th>\n",
       "<th>Rate</th></tr></thead>\n",
       "    <tbody><tr><td>0</td>\n",
       "<td>107854.0</td>\n",
       "<td>24152.0</td>\n",
       "<td>0.183</td>\n",
       "<td> (24152.0/132006.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>12732.0</td>\n",
       "<td>15313.0</td>\n",
       "<td>0.454</td>\n",
       "<td> (12732.0/28045.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>120586.0</td>\n",
       "<td>39465.0</td>\n",
       "<td>0.2305</td>\n",
       "<td> (36884.0/160051.0)</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-3.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-3 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-3 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-3 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-3 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-3 .h2o-table th,\n",
       "#h2o-table-3 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-3 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-3\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
       "    <thead><tr><th>metric</th>\n",
       "<th>threshold</th>\n",
       "<th>value</th>\n",
       "<th>idx</th></tr></thead>\n",
       "    <tbody><tr><td>max f1</td>\n",
       "<td>0.2596066</td>\n",
       "<td>0.4536513</td>\n",
       "<td>181.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.1416101</td>\n",
       "<td>0.5833299</td>\n",
       "<td>276.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.3355759</td>\n",
       "<td>0.4484524</td>\n",
       "<td>131.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.4400400</td>\n",
       "<td>0.8344278</td>\n",
       "<td>76.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9563438</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0059092</td>\n",
       "<td>1.0</td>\n",
       "<td>396.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9563438</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.2905098</td>\n",
       "<td>0.3209073</td>\n",
       "<td>160.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.1986666</td>\n",
       "<td>0.6913888</td>\n",
       "<td>228.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.2096354</td>\n",
       "<td>0.6921867</td>\n",
       "<td>219.0</td></tr>\n",
       "<tr><td>max tns</td>\n",
       "<td>0.9563438</td>\n",
       "<td>132006.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fns</td>\n",
       "<td>0.9563438</td>\n",
       "<td>28042.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fps</td>\n",
       "<td>0.0027768</td>\n",
       "<td>132006.0</td>\n",
       "<td>399.0</td></tr>\n",
       "<tr><td>max tps</td>\n",
       "<td>0.0059092</td>\n",
       "<td>28045.0</td>\n",
       "<td>396.0</td></tr>\n",
       "<tr><td>max tnr</td>\n",
       "<td>0.9563438</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fnr</td>\n",
       "<td>0.9563438</td>\n",
       "<td>0.9998930</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fpr</td>\n",
       "<td>0.0027768</td>\n",
       "<td>1.0</td>\n",
       "<td>399.0</td></tr>\n",
       "<tr><td>max tpr</td>\n",
       "<td>0.0059092</td>\n",
       "<td>1.0</td>\n",
       "<td>396.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-4.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-4 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-4 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-4 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-4 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-4 .h2o-table th,\n",
       "#h2o-table-4 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-4 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-4\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Gains/Lift Table: Avg response rate: 17.52 %, avg score: 17.63 %</caption>\n",
       "    <thead><tr><th>group</th>\n",
       "<th>cumulative_data_fraction</th>\n",
       "<th>lower_threshold</th>\n",
       "<th>lift</th>\n",
       "<th>cumulative_lift</th>\n",
       "<th>response_rate</th>\n",
       "<th>score</th>\n",
       "<th>cumulative_response_rate</th>\n",
       "<th>cumulative_score</th>\n",
       "<th>capture_rate</th>\n",
       "<th>cumulative_capture_rate</th>\n",
       "<th>gain</th>\n",
       "<th>cumulative_gain</th>\n",
       "<th>kolmogorov_smirnov</th></tr></thead>\n",
       "    <tbody><tr><td>1</td>\n",
       "<td>0.0100031</td>\n",
       "<td>0.5337985</td>\n",
       "<td>4.4343707</td>\n",
       "<td>4.4343707</td>\n",
       "<td>0.7770144</td>\n",
       "<td>0.5941140</td>\n",
       "<td>0.7770144</td>\n",
       "<td>0.5941140</td>\n",
       "<td>0.0443573</td>\n",
       "<td>0.0443573</td>\n",
       "<td>343.4370701</td>\n",
       "<td>343.4370701</td>\n",
       "<td>0.0416529</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.0200061</td>\n",
       "<td>0.4831532</td>\n",
       "<td>3.5182668</td>\n",
       "<td>3.9763187</td>\n",
       "<td>0.6164897</td>\n",
       "<td>0.5056358</td>\n",
       "<td>0.6967520</td>\n",
       "<td>0.5498749</td>\n",
       "<td>0.0351934</td>\n",
       "<td>0.0795507</td>\n",
       "<td>251.8266786</td>\n",
       "<td>297.6318743</td>\n",
       "<td>0.0721950</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.0300029</td>\n",
       "<td>0.4535195</td>\n",
       "<td>3.2065843</td>\n",
       "<td>3.7198474</td>\n",
       "<td>0.561875</td>\n",
       "<td>0.4671955</td>\n",
       "<td>0.6518117</td>\n",
       "<td>0.5223266</td>\n",
       "<td>0.0320556</td>\n",
       "<td>0.1116063</td>\n",
       "<td>220.6584262</td>\n",
       "<td>271.9847446</td>\n",
       "<td>0.0989403</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.0400060</td>\n",
       "<td>0.4301179</td>\n",
       "<td>2.9871404</td>\n",
       "<td>3.5366421</td>\n",
       "<td>0.5234229</td>\n",
       "<td>0.4413947</td>\n",
       "<td>0.6197095</td>\n",
       "<td>0.5020905</td>\n",
       "<td>0.0298805</td>\n",
       "<td>0.1414869</td>\n",
       "<td>198.7140392</td>\n",
       "<td>253.6642074</td>\n",
       "<td>0.1230408</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.0500028</td>\n",
       "<td>0.4133681</td>\n",
       "<td>2.6715591</td>\n",
       "<td>3.3636903</td>\n",
       "<td>0.468125</td>\n",
       "<td>0.4213128</td>\n",
       "<td>0.5894040</td>\n",
       "<td>0.4859410</td>\n",
       "<td>0.0267071</td>\n",
       "<td>0.1681940</td>\n",
       "<td>167.1559079</td>\n",
       "<td>236.3690332</td>\n",
       "<td>0.1433012</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.1000056</td>\n",
       "<td>0.3585482</td>\n",
       "<td>2.4466444</td>\n",
       "<td>2.9051674</td>\n",
       "<td>0.4287142</td>\n",
       "<td>0.3834831</td>\n",
       "<td>0.5090591</td>\n",
       "<td>0.4347121</td>\n",
       "<td>0.1223391</td>\n",
       "<td>0.2905331</td>\n",
       "<td>144.6644378</td>\n",
       "<td>190.5167355</td>\n",
       "<td>0.2310055</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.1500022</td>\n",
       "<td>0.3189827</td>\n",
       "<td>2.0903558</td>\n",
       "<td>2.6335861</td>\n",
       "<td>0.3662834</td>\n",
       "<td>0.3382908</td>\n",
       "<td>0.4614712</td>\n",
       "<td>0.4025743</td>\n",
       "<td>0.1045106</td>\n",
       "<td>0.3950437</td>\n",
       "<td>109.0355825</td>\n",
       "<td>163.3586138</td>\n",
       "<td>0.2971012</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>0.2000050</td>\n",
       "<td>0.2858815</td>\n",
       "<td>1.6465467</td>\n",
       "<td>2.3868186</td>\n",
       "<td>0.2885168</td>\n",
       "<td>0.3019349</td>\n",
       "<td>0.4182312</td>\n",
       "<td>0.3774137</td>\n",
       "<td>0.0823320</td>\n",
       "<td>0.4773756</td>\n",
       "<td>64.6546741</td>\n",
       "<td>138.6818580</td>\n",
       "<td>0.3362987</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>0.3000044</td>\n",
       "<td>0.2323140</td>\n",
       "<td>1.3414240</td>\n",
       "<td>2.0383610</td>\n",
       "<td>0.2350515</td>\n",
       "<td>0.2578616</td>\n",
       "<td>0.3571726</td>\n",
       "<td>0.3375638</td>\n",
       "<td>0.1341416</td>\n",
       "<td>0.6115172</td>\n",
       "<td>34.1423963</td>\n",
       "<td>103.8360965</td>\n",
       "<td>0.3776945</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>0.4000037</td>\n",
       "<td>0.1877919</td>\n",
       "<td>1.0408337</td>\n",
       "<td>1.7889831</td>\n",
       "<td>0.1823805</td>\n",
       "<td>0.2095390</td>\n",
       "<td>0.3134753</td>\n",
       "<td>0.3055581</td>\n",
       "<td>0.1040827</td>\n",
       "<td>0.7155999</td>\n",
       "<td>4.0833745</td>\n",
       "<td>78.8983055</td>\n",
       "<td>0.3826454</td></tr>\n",
       "<tr><td>11</td>\n",
       "<td>0.5000031</td>\n",
       "<td>0.1475687</td>\n",
       "<td>0.8297431</td>\n",
       "<td>1.5971375</td>\n",
       "<td>0.1453921</td>\n",
       "<td>0.1672571</td>\n",
       "<td>0.2798590</td>\n",
       "<td>0.2778983</td>\n",
       "<td>0.0829738</td>\n",
       "<td>0.7985737</td>\n",
       "<td>-17.0256895</td>\n",
       "<td>59.7137463</td>\n",
       "<td>0.3620027</td></tr>\n",
       "<tr><td>12</td>\n",
       "<td>0.6000025</td>\n",
       "<td>0.1129214</td>\n",
       "<td>0.6357679</td>\n",
       "<td>1.4369109</td>\n",
       "<td>0.1114027</td>\n",
       "<td>0.1296607</td>\n",
       "<td>0.2517833</td>\n",
       "<td>0.2531923</td>\n",
       "<td>0.0635764</td>\n",
       "<td>0.8621501</td>\n",
       "<td>-36.4232077</td>\n",
       "<td>43.6910875</td>\n",
       "<td>0.3178415</td></tr>\n",
       "<tr><td>13</td>\n",
       "<td>0.7000019</td>\n",
       "<td>0.0862244</td>\n",
       "<td>0.5084717</td>\n",
       "<td>1.3042779</td>\n",
       "<td>0.0890972</td>\n",
       "<td>0.0988675</td>\n",
       "<td>0.2285426</td>\n",
       "<td>0.2311461</td>\n",
       "<td>0.0508469</td>\n",
       "<td>0.9129970</td>\n",
       "<td>-49.1528290</td>\n",
       "<td>30.4277892</td>\n",
       "<td>0.2582464</td></tr>\n",
       "<tr><td>14</td>\n",
       "<td>0.8000012</td>\n",
       "<td>0.0639966</td>\n",
       "<td>0.4318087</td>\n",
       "<td>1.1952201</td>\n",
       "<td>0.0756639</td>\n",
       "<td>0.0750344</td>\n",
       "<td>0.2094329</td>\n",
       "<td>0.2116322</td>\n",
       "<td>0.0431806</td>\n",
       "<td>0.9561776</td>\n",
       "<td>-56.8191276</td>\n",
       "<td>19.5220098</td>\n",
       "<td>0.1893564</td></tr>\n",
       "<tr><td>15</td>\n",
       "<td>0.9000006</td>\n",
       "<td>0.0391157</td>\n",
       "<td>0.3451617</td>\n",
       "<td>1.1007698</td>\n",
       "<td>0.0604811</td>\n",
       "<td>0.0525234</td>\n",
       "<td>0.1928828</td>\n",
       "<td>0.1939536</td>\n",
       "<td>0.0345160</td>\n",
       "<td>0.9906935</td>\n",
       "<td>-65.4838278</td>\n",
       "<td>10.0769823</td>\n",
       "<td>0.1099608</td></tr>\n",
       "<tr><td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0003016</td>\n",
       "<td>0.0930653</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0163074</td>\n",
       "<td>0.0175428</td>\n",
       "<td>0.1752254</td>\n",
       "<td>0.1763126</td>\n",
       "<td>0.0093065</td>\n",
       "<td>1.0</td>\n",
       "<td>-90.6934701</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>"
      ],
      "text/plain": [
       "ModelMetricsBinomialGLM: glm\n",
       "** Reported on test data. **\n",
       "\n",
       "MSE: 0.12413049522770588\n",
       "RMSE: 0.3523215792819195\n",
       "LogLoss: 0.39754376074662856\n",
       "AUC: 0.7609598349213056\n",
       "AUCPR: 0.4307181079129981\n",
       "Gini: 0.5219196698426112\n",
       "Null degrees of freedom: 160050\n",
       "Residual degrees of freedom: 65807\n",
       "Null deviance: 148551.6010573488\n",
       "Residual deviance: 127254.55290251729\n",
       "AIC: 315742.55290251726\n",
       "\n",
       "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.25960656340740557\n",
       "       0       1      Error    Rate\n",
       "-----  ------  -----  -------  ------------------\n",
       "0      107854  24152  0.183    (24152.0/132006.0)\n",
       "1      12732   15313  0.454    (12732.0/28045.0)\n",
       "Total  120586  39465  0.2305   (36884.0/160051.0)\n",
       "\n",
       "Maximum Metrics: Maximum metrics at their respective thresholds\n",
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.259607     0.453651  181\n",
       "max f2                       0.14161      0.58333   276\n",
       "max f0point5                 0.335576     0.448452  131\n",
       "max accuracy                 0.44004      0.834428  76\n",
       "max precision                0.956344     1         0\n",
       "max recall                   0.00590915   1         396\n",
       "max specificity              0.956344     1         0\n",
       "max absolute_mcc             0.29051      0.320907  160\n",
       "max min_per_class_accuracy   0.198667     0.691389  228\n",
       "max mean_per_class_accuracy  0.209635     0.692187  219\n",
       "max tns                      0.956344     132006    0\n",
       "max fns                      0.956344     28042     0\n",
       "max fps                      0.00277683   132006    399\n",
       "max tps                      0.00590915   28045     396\n",
       "max tnr                      0.956344     1         0\n",
       "max fnr                      0.956344     0.999893  0\n",
       "max fpr                      0.00277683   1         399\n",
       "max tpr                      0.00590915   1         396\n",
       "\n",
       "Gains/Lift Table: Avg response rate: 17.52 %, avg score: 17.63 %\n",
       "group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
       "-------  --------------------------  -----------------  ---------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
       "1        0.0100031                   0.533798           4.43437    4.43437            0.777014         0.594114   0.777014                    0.594114            0.0443573       0.0443573                  343.437   343.437            0.0416529\n",
       "2        0.0200061                   0.483153           3.51827    3.97632            0.61649          0.505636   0.696752                    0.549875            0.0351934       0.0795507                  251.827   297.632            0.072195\n",
       "3        0.0300029                   0.453519           3.20658    3.71985            0.561875         0.467196   0.651812                    0.522327            0.0320556       0.111606                   220.658   271.985            0.0989403\n",
       "4        0.040006                    0.430118           2.98714    3.53664            0.523423         0.441395   0.61971                     0.50209             0.0298805       0.141487                   198.714   253.664            0.123041\n",
       "5        0.0500028                   0.413368           2.67156    3.36369            0.468125         0.421313   0.589404                    0.485941            0.0267071       0.168194                   167.156   236.369            0.143301\n",
       "6        0.100006                    0.358548           2.44664    2.90517            0.428714         0.383483   0.509059                    0.434712            0.122339        0.290533                   144.664   190.517            0.231005\n",
       "7        0.150002                    0.318983           2.09036    2.63359            0.366283         0.338291   0.461471                    0.402574            0.104511        0.395044                   109.036   163.359            0.297101\n",
       "8        0.200005                    0.285881           1.64655    2.38682            0.288517         0.301935   0.418231                    0.377414            0.082332        0.477376                   64.6547   138.682            0.336299\n",
       "9        0.300004                    0.232314           1.34142    2.03836            0.235052         0.257862   0.357173                    0.337564            0.134142        0.611517                   34.1424   103.836            0.377694\n",
       "10       0.400004                    0.187792           1.04083    1.78898            0.182381         0.209539   0.313475                    0.305558            0.104083        0.7156                     4.08337   78.8983            0.382645\n",
       "11       0.500003                    0.147569           0.829743   1.59714            0.145392         0.167257   0.279859                    0.277898            0.0829738       0.798574                   -17.0257  59.7137            0.362003\n",
       "12       0.600002                    0.112921           0.635768   1.43691            0.111403         0.129661   0.251783                    0.253192            0.0635764       0.86215                    -36.4232  43.6911            0.317842\n",
       "13       0.700002                    0.0862244          0.508472   1.30428            0.0890972        0.0988675  0.228543                    0.231146            0.0508469       0.912997                   -49.1528  30.4278            0.258246\n",
       "14       0.800001                    0.0639966          0.431809   1.19522            0.0756639        0.0750344  0.209433                    0.211632            0.0431806       0.956178                   -56.8191  19.522             0.189356\n",
       "15       0.900001                    0.0391157          0.345162   1.10077            0.0604811        0.0525234  0.192883                    0.193954            0.034516        0.990694                   -65.4838  10.077             0.109961\n",
       "16       1                           0.000301557        0.0930653  1                  0.0163074        0.0175428  0.175225                    0.176313            0.00930647      1                          -90.6935  0                  0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glm_binom.model_performance(h2o_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b283d4-3b80-4f09-8adb-fe4925758229",
   "metadata": {},
   "source": [
    "From the confusion matrix, we can see that the model is struggling to correctly classify the Class 1 instances. It may be due to the class imbalances in the data or not enough features that are significant enough for the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be12916-0ca9-48f5-b9f2-6762929c1b39",
   "metadata": {},
   "source": [
    "#### Step 14: <span style=\"color:yellow\">Hyper tune the GLM with hyper parameters and find the best parameters.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "095321ac-1a55-4afb-a0cb-561f19f9be6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glm Grid Build progress: |███████████████████████████████████████████████████████| (done) 100%\n",
      "Model Details\n",
      "=============\n",
      "H2OGeneralizedLinearEstimator : Generalized Linear Modeling\n",
      "Model Key: Grid_GLM_py_1_sid_ad88_model_python_1720240142070_4_model_1\n",
      "\n",
      "\n",
      "GLM Model: summary\n",
      "    family    link    regularization             number_of_predictors_total    number_of_active_predictors    number_of_iterations    training_frame\n",
      "--  --------  ------  -------------------------  ----------------------------  -----------------------------  ----------------------  ----------------\n",
      "    binomial  logit   Ridge ( lambda = 1.0E-4 )  94244                         94243                          68                      py_1_sid_ad88\n",
      "\n",
      "ModelMetricsBinomialGLM: glm\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.1172288020623717\n",
      "RMSE: 0.3423869186496057\n",
      "LogLoss: 0.37638208822494584\n",
      "AUC: 0.7921747277919343\n",
      "AUCPR: 0.48332582245019046\n",
      "Gini: 0.5843494555838686\n",
      "Null degrees of freedom: 480152\n",
      "Residual degrees of freedom: 385909\n",
      "Null deviance: 445859.15054967126\n",
      "Residual deviance: 361441.97761494486\n",
      "AIC: 549929.9776149448\n",
      "\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.24808936670883533\n",
      "       0       1       Error    Rate\n",
      "-----  ------  ------  -------  -------------------\n",
      "0      326670  69282   0.175    (69282.0/395952.0)\n",
      "1      34463   49738   0.4093   (34463.0/84201.0)\n",
      "Total  361133  119020  0.2161   (103745.0/480153.0)\n",
      "\n",
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "metric                       threshold    value     idx\n",
      "---------------------------  -----------  --------  -----\n",
      "max f1                       0.248089     0.489497  216\n",
      "max f2                       0.131379     0.605548  293\n",
      "max f0point5                 0.370458     0.492268  151\n",
      "max accuracy                 0.488826     0.841034  99\n",
      "max precision                0.982143     1         0\n",
      "max recall                   0.000940799  1         399\n",
      "max specificity              0.982143     1         0\n",
      "max absolute_mcc             0.286939     0.36901   193\n",
      "max min_per_class_accuracy   0.184358     0.715473  255\n",
      "max mean_per_class_accuracy  0.198625     0.716956  246\n",
      "max tns                      0.982143     395952    0\n",
      "max fns                      0.982143     84183     0\n",
      "max fps                      0.000940799  395952    399\n",
      "max tps                      0.000940799  84201     399\n",
      "max tnr                      0.982143     1         0\n",
      "max fnr                      0.982143     0.999786  0\n",
      "max fpr                      0.000940799  1         399\n",
      "max tpr                      0.000940799  1         399\n",
      "\n",
      "Gains/Lift Table: Avg response rate: 17.54 %, avg score: 17.53 %\n",
      "group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain       cumulative_gain    kolmogorov_smirnov\n",
      "-------  --------------------------  -----------------  ---------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  ---------  -----------------  --------------------\n",
      "1        0.010001                    0.693905           4.62301    4.62301            0.810704         0.746471    0.810704                    0.746471            0.0462346       0.0462346                  362.301    362.301            0.0439389\n",
      "2        0.020002                    0.623576           4.205      4.414              0.737401         0.657716    0.774052                    0.702093            0.0420541       0.0882887                  320.5      341.4              0.0828083\n",
      "3        0.0300009                   0.566721           3.72721    4.1851             0.653614         0.594056    0.733912                    0.666086            0.037268        0.125557                   272.721    318.51             0.115876\n",
      "4        0.0400018                   0.526255           3.3298     3.97127            0.583923         0.545472    0.696413                    0.635931            0.0333013       0.158858                   232.98     297.127            0.144131\n",
      "5        0.0500007                   0.496951           3.00505    3.77805            0.526974         0.510775    0.662529                    0.610903            0.0300471       0.188905                   200.505    277.805            0.168443\n",
      "6        0.100001                    0.399058           2.63865    3.20835            0.462721         0.443322    0.562625                    0.527112            0.131934        0.320839                   163.865    220.835            0.2678\n",
      "7        0.15                        0.335185           2.20122    2.87265            0.386012         0.365539    0.503756                    0.473256            0.110058        0.430897                   120.122    187.265            0.340632\n",
      "8        0.200001                    0.284903           1.78119    2.59978            0.312354         0.308839    0.455905                    0.432151            0.0890607       0.519958                   78.1188    159.978            0.387998\n",
      "9        0.3                         0.214798           1.34156    2.18038            0.23526          0.247206    0.382357                    0.370503            0.134155        0.654113                   34.156     118.038            0.429417\n",
      "10       0.4                         0.165415           0.992156   1.88332            0.173987         0.189       0.330265                    0.325128            0.099215        0.753328                   -0.784406  88.3323            0.428466\n",
      "11       0.500001                    0.127252           0.757462   1.65815            0.132831         0.145558    0.290778                    0.289213            0.0757473       0.829076                   -24.2538   65.8148            0.399054\n",
      "12       0.6                         0.0980905          0.59394    1.48078            0.104155         0.112159    0.259674                    0.259704            0.0593936       0.888469                   -40.606    48.0781            0.349813\n",
      "13       0.7                         0.0735887          0.475769   1.33721            0.0834323        0.0855425   0.234497                    0.234824            0.0475766       0.936046                   -52.4231   33.7209            0.286242\n",
      "14       0.799999                    0.0519007          0.347029   1.21344            0.060856         0.0626123   0.212792                    0.213298            0.0347027       0.970749                   -65.2971   21.3437            0.20706\n",
      "15       0.899999                    0.0265365          0.250117   1.1064             0.0438613        0.0402742   0.194022                    0.194073            0.0250116       0.99576                    -74.9883   10.6402            0.116126\n",
      "16       1                           1.6601e-23         0.0423979  1                  0.00743502       0.00675672  0.175363                    0.175341            0.00423985      1                          -95.7602   0                  0\n",
      "\n",
      "ModelMetricsBinomialGLM: glm\n",
      "** Reported on validation data. **\n",
      "\n",
      "MSE: 0.11870158069364133\n",
      "RMSE: 0.34453095752579527\n",
      "LogLoss: 0.3823158953059858\n",
      "AUC: 0.7840751715778426\n",
      "AUCPR: 0.46899099180018944\n",
      "Gini: 0.5681503431556851\n",
      "Null degrees of freedom: 160050\n",
      "Residual degrees of freedom: 65807\n",
      "Null deviance: 148551.6010573488\n",
      "Residual deviance: 122380.08271923667\n",
      "AIC: 310868.08271923667\n",
      "\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.26414206674589324\n",
      "       0       1      Error    Rate\n",
      "-----  ------  -----  -------  ------------------\n",
      "0      111362  20644  0.1564   (20644.0/132006.0)\n",
      "1      12580   15465  0.4486   (12580.0/28045.0)\n",
      "Total  123942  36109  0.2076   (33224.0/160051.0)\n",
      "\n",
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "metric                       threshold    value     idx\n",
      "---------------------------  -----------  --------  -----\n",
      "max f1                       0.264142     0.482121  201\n",
      "max f2                       0.126047     0.599398  295\n",
      "max f0point5                 0.361578     0.48025   149\n",
      "max accuracy                 0.489747     0.83927   92\n",
      "max precision                0.976636     1         0\n",
      "max recall                   0.000794837  1         399\n",
      "max specificity              0.976636     1         0\n",
      "max absolute_mcc             0.279244     0.360583  193\n",
      "max min_per_class_accuracy   0.182169     0.709498  253\n",
      "max mean_per_class_accuracy  0.196856     0.710148  242\n",
      "max tns                      0.976636     132006    0\n",
      "max fns                      0.976636     28043     0\n",
      "max fps                      0.000794837  132006    399\n",
      "max tps                      0.000794837  28045     399\n",
      "max tnr                      0.976636     1         0\n",
      "max fnr                      0.976636     0.999929  0\n",
      "max fpr                      0.000794837  1         399\n",
      "max tpr                      0.000794837  1         399\n",
      "\n",
      "Gains/Lift Table: Avg response rate: 17.52 %, avg score: 17.50 %\n",
      "group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
      "-------  --------------------------  -----------------  ---------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
      "1        0.0100031                   0.693161           4.53418    4.53418            0.794503         0.746233    0.794503                    0.746233            0.0453557       0.0453557                  353.418   353.418            0.0428634\n",
      "2        0.0200061                   0.620299           4.10286    4.31852            0.718926         0.655686    0.756715                    0.70096             0.0410412       0.0863969                  310.286   331.852            0.0804956\n",
      "3        0.0300029                   0.564346           3.60607    4.08114            0.631875         0.591228    0.715119                    0.664398            0.0360492       0.122446                   260.607   308.114            0.112083\n",
      "4        0.040006                    0.52619            3.19745    3.86018            0.560275         0.544273    0.676402                    0.634362            0.0319843       0.15443                    219.745   286.018            0.138734\n",
      "5        0.0500028                   0.496638           2.89627    3.66747            0.5075           0.51097     0.642634                    0.609693            0.0289535       0.183384                   189.627   266.747            0.161718\n",
      "6        0.100006                    0.399194           2.59568    3.13158            0.454829         0.442904    0.548732                    0.526298            0.129791        0.313175                   159.568   213.158            0.258458\n",
      "7        0.150002                    0.334933           2.17309    2.81211            0.38078          0.365713    0.492752                    0.472774            0.108647        0.421822                   117.309   181.211            0.329569\n",
      "8        0.200005                    0.28446            1.82054    2.56421            0.319005         0.308717    0.449314                    0.431759            0.0910323       0.512854                   82.0543   156.421            0.379315\n",
      "9        0.300004                    0.213981           1.3186     2.14901            0.231053         0.246595    0.376562                    0.370039            0.13186         0.644714                   31.8603   114.901            0.417944\n",
      "10       0.400004                    0.165387           0.988774   1.85896            0.173258         0.188698    0.325737                    0.324704            0.0988768       0.743591                   -1.12258  85.8959            0.416583\n",
      "11       0.500003                    0.127089           0.77697    1.64256            0.136145         0.145342    0.287819                    0.288832            0.0776966       0.821287                   -22.303   64.2564            0.389542\n",
      "12       0.600002                    0.0977402          0.608668   1.47025            0.106654         0.111902    0.257625                    0.259344            0.0608665       0.882154                   -39.1332  47.025             0.342095\n",
      "13       0.700002                    0.0733604          0.473528   1.32786            0.0829741        0.0850795   0.232675                    0.234449            0.0473525       0.929506                   -52.6472  32.7862            0.278263\n",
      "14       0.800001                    0.0516152          0.375114   1.20877            0.0657295        0.0623072   0.211807                    0.212932            0.0375111       0.967017                   -62.4886  20.877             0.202499\n",
      "15       0.900001                    0.0257248          0.256019   1.10291            0.044861         0.0399048   0.193258                    0.193707            0.0256017       0.992619                   -74.3981  10.2909            0.112295\n",
      "16       1                           1.84028e-05        0.0738104  1                  0.0129335        0.00618603  0.175225                    0.174955            0.00738099      1                          -92.619   0                  0\n",
      "\n",
      "Scoring History: \n",
      "     timestamp            duration    iterations    negative_log_likelihood    objective            training_rmse       training_logloss     training_r2         training_auc        training_pr_auc      training_lift      training_classification_error    validation_rmse      validation_logloss    validation_r2        validation_auc      validation_pr_auc    validation_lift    validation_classification_error\n",
      "---  -------------------  ----------  ------------  -------------------------  -------------------  ------------------  -------------------  ------------------  ------------------  -------------------  -----------------  -------------------------------  -------------------  --------------------  -------------------  ------------------  -------------------  -----------------  ---------------------------------\n",
      "     2024-07-06 01:59:40  0.000 sec   0             222929.57527483563         0.4642886231572762\n",
      "     2024-07-06 01:59:40  0.069 sec   1             206595.32939533592         0.4302741363670416\n",
      "     2024-07-06 01:59:40  0.127 sec   2             200057.17564118665         0.41666645343851816\n",
      "     2024-07-06 01:59:40  0.202 sec   3             198036.07985686173         0.4124674446433359\n",
      "     2024-07-06 01:59:40  0.260 sec   4             195828.65939327254         0.4078791730115865\n",
      "     2024-07-06 01:59:40  0.314 sec   5             193600.85106823067         0.40325284528735533\n",
      "     2024-07-06 01:59:40  0.378 sec   6             193101.14561437618         0.4022291982954877\n",
      "     2024-07-06 01:59:40  0.425 sec   7             192179.5705937763          0.4003283582060791\n",
      "     2024-07-06 01:59:40  0.472 sec   8             191827.20552851827         0.3995968891180355\n",
      "     2024-07-06 01:59:40  0.550 sec   9             191044.50963157523         0.39798298461933085\n",
      "---  ---                  ---         ---           ---                        ---                  ---                 ---                  ---                 ---                 ---                  ---                ---                              ---                  ---                   ---                  ---                 ---                  ---                ---\n",
      "     2024-07-06 01:59:44  4.290 sec   59            181304.96132206026         0.3808054390925121\n",
      "     2024-07-06 01:59:44  4.337 sec   60            181268.43728610524         0.38074170476144686\n",
      "     2024-07-06 01:59:44  4.446 sec   61            181173.53204432165         0.3806590290246129\n",
      "     2024-07-06 01:59:44  4.493 sec   62            181120.97749369632         0.3805865831325264\n",
      "     2024-07-06 01:59:44  4.619 sec   63            181035.96200254638         0.380532546604138\n",
      "     2024-07-06 01:59:45  4.699 sec   64            180926.689974704           0.38048953677814557\n",
      "     2024-07-06 01:59:45  4.790 sec   65            180796.53740691702         0.3803838038637587\n",
      "     2024-07-06 01:59:45  4.852 sec   66            180763.9080368856          0.3803094233197457\n",
      "     2024-07-06 01:59:45  4.884 sec   67            180744.0193525013          0.3802533043050722\n",
      "     2024-07-06 01:59:45  4.946 sec   68            180720.98880747243         0.38023151718448467  0.3423869186496057  0.37638208822494584  0.1893491730430079  0.7921747277919343  0.48332582245019046  4.623008003681083  0.2160665454553028               0.34453095752579527  0.3823158953059858    0.17865773701509036  0.7840751715778426  0.46899099180018944  4.534179687347752  0.20758383265334174\n",
      "[69 rows x 20 columns]\n",
      "\n",
      "\n",
      "Variable Importances: \n",
      "variable                            relative_importance     scaled_importance       percentage\n",
      "----------------------------------  ----------------------  ----------------------  ----------------------\n",
      "Bank.SUPERIOR FINANCIAL GROUP, LLC  2.0799617767333984      1.0                     0.0020365634567530103\n",
      "Bank.BBCN BANK                      1.695399522781372       0.815110903357087       0.001660025078977978\n",
      "Bank.INNOVATIVE BANK                1.341563105583191       0.6449941150794269      0.0013135714445915068\n",
      "BankState.DE                        1.251476764678955       0.6016825783425753      0.0012253647516174192\n",
      "Bank.BANCO POPULAR NORTH AMERICA    1.243520736694336       0.5978574945965104      0.0012175747258411636\n",
      "Bank.READYCAP LENDING, LLC          1.1648973226547241      0.5600570816662831      0.0011405917862172886\n",
      "Zip.0                               1.1570323705673218      0.556275785213925       0.0011328909360432662\n",
      "Bank.TD BANK, NATIONAL ASSOCIATION  1.002441167831421       0.4819517257695789      0.0009815252726213725\n",
      "BankState.VA                        0.9910134673118591      0.4764575380169996      0.0009703360106199296\n",
      "Bank_UR                             0.9715256094932556      0.46708820342797197     0.0009512547661818239\n",
      "---                                 ---                     ---                     ---\n",
      "City.South amboy                    2.6133650408155518e-06  1.2564485896081556e-06  2.55883728288483e-09\n",
      "City_State.Colierville_TN           1.983656375159626e-06   9.536984753032236e-07   1.9422674635636087e-09\n",
      "City.Colierville                    1.983656375159626e-06   9.536984753032236e-07   1.9422674635636087e-09\n",
      "Zip.71235                           1.8744303815765306e-06  9.011850133709394e-07   1.8353204660047284e-09\n",
      "City.Anderson                       1.6730298284528544e-06  8.043560449848098e-07   1.6381221274344444e-09\n",
      "Zip.35611                           1.2609056057044654e-06  6.062157582937561e-07   1.2345968602488795e-09\n",
      "City_State.Bloomfield hills_MI      1.210468212775595e-06   5.819665660763478e-07   1.1852118415231261e-09\n",
      "City.Bloomfield hills               1.210468212775595e-06   5.819665660763478e-07   1.1852118415231261e-09\n",
      "Zip.53954                           7.301622986233269e-07   3.510460176677162e-07   7.149274912207425e-10\n",
      "FranchiseCode.0                     0.0                     0.0                     0.0\n",
      "[94244 rows x 4 columns]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from h2o.grid.grid_search import H2OGridSearch\n",
    "glm_model = H2OGeneralizedLinearEstimator(\n",
    "    model_id=\"glm_hypertune\",\n",
    "    solver=\"L_BFGS\",\n",
    "    family=\"binomial\",\n",
    "    max_iterations=2000,\n",
    ")\n",
    "# Define the hyperparameters\n",
    "hyper_params = {\n",
    "    'alpha': [0, 0.1, 0.25, 0.5, 0.75],   # 5 values\n",
    "    'lambda': [1e-4, 5e-4, 1e-3, 5e-3, 1e-2, 5e-2, 0.1, 0.5, 1, 5]   # 10 values\n",
    "}\n",
    "\n",
    "# Perform grid search\n",
    "grid = H2OGridSearch(\n",
    "    model=glm_model,\n",
    "    hyper_params=hyper_params,\n",
    "    search_criteria={'strategy': 'Cartesian'}  # Ensure all combinations are used\n",
    ")\n",
    "\n",
    "# Train grid search\n",
    "grid.train(\n",
    "    x=covtype_X, y=covtype_y, training_frame=h2o_train,validation_frame=h2o_val\n",
    ")\n",
    "# Get the grid search results\n",
    "grid_results = grid.get_grid(\n",
    "    sort_by='auc', \n",
    "    decreasing=True\n",
    ")\n",
    "\n",
    "# Print the grid search results\n",
    "print(grid_results[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162d9237-d892-4404-ad50-dec34a49d411",
   "metadata": {},
   "source": [
    "#### Step 15: <span style=\"color:yellow\">Lets store the best model found into a variable so that we can test its performance on the test data.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc74846-0b9f-4263-ad30-7cd97a0f01cd",
   "metadata": {},
   "source": [
    "From the grid search we can get the best parameters alpha and lambda. But since the best model was already trained on the training dataframe.We can use the same model for further steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "65406dcb-b05b-4fd7-b215-6cf44d4d7643",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_h2o = grid_results.models[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7cc8423-4476-4d2e-8dbc-7eb6ba872518",
   "metadata": {},
   "source": [
    "#### Step 16: <span style=\"color:yellow\">Use test data to evaluate AUC using both scikit and H2O model. Choose the model that gives the best AUC score as the best model</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dd89ba22-7220-4fe2-af9c-a43aa9e88272",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7839297878334643"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perf_h2o = best_model_h2o.model_performance(h2o_test).auc()\n",
    "perf_h2o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0f925eb8-2867-42e4-b24f-669128b8b4ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.767999098779764"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_probtest = bestmodel.predict_proba(X_test)[:, 1]\n",
    "roc_auc_test = roc_auc_score(y_test, y_pred_probtest)\n",
    "roc_auc_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebb1cf7-eeea-4442-b5bf-67191f46315e",
   "metadata": {},
   "source": [
    "#### Step 17: <span style=\"color:yellow\">Since we found that H2O GLM gives a better AUC compared to Scikit Log regression on the test data. We extract the threshold that maximizes the F1 score from the model and store it into artifacts.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ba08e489-1907-4ed3-8ee2-360753f09e87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24808936670883533"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract F1 scores at different thresholds\n",
    "max_f1_threshold = best_model_h2o.model_performance(h2o_train).find_threshold_by_max_metric('f1')\n",
    "max_f1_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "82f5c97e-2023-4036-9738-7c94bc8ed5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "artifacts_dict[\"threshold\"] = max_f1_threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0afa010a-cfad-4117-9701-0a154d873853",
   "metadata": {},
   "source": [
    "#### Step 18: <span style=\"color:yellow\">Save the H2O model into the artifacts folder and dump the artifacts dictionary and functions into the artifacts folder using pickle.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d3087001-9023-46ab-9d8d-df376c2268d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "artifacts_dict[\"ModelPath\"] = 'artifacts/'+best_model_h2o.model_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "75f23bc7-9c39-4313-b9ca-4a9273d81b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "h2o.save_model(model=best_model_h2o,path=\"../artifacts\",force=True)\n",
    "artifacts_functions_file = open(\"../artifacts/artifacts_functions_file.pkl\", \"wb\")\n",
    "pickle.dump(obj=artifacts_functions, file=artifacts_functions_file)\n",
    "artifacts_functions_file.close()\n",
    "artifacts_dict_file = open(\"../artifacts/artifacts_dict_file.pkl\", \"wb\")\n",
    "pickle.dump(obj=artifacts_dict, file=artifacts_dict_file)\n",
    "artifacts_dict_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae24423-36c2-414d-9874-7e1e2ce11029",
   "metadata": {},
   "source": [
    "### Conclusion and Findings on Logistic Regression and H2O GLM Models\r\n",
    "\r\n",
    "## Overview\n",
    "De developed two predictive models predictast the outcome of SBA loans based on several featureFirst model being the Scikitard Logistic Regression model asecond nd a Generalized Linear Model (GLM) using the H2O framework. \r\n",
    "\r\n",
    "#### Model Performance\r\n",
    "\r\n",
    "1. **Logistic Regression Model:**\r\n",
    "   - **AUC (Area Under the Curve):** 76.7\r\n",
    "   - **Interpretation:** An AUC of 76.7% indicates that the Logistic Regression model has a good ability to distinguish between the positive and negative classes. The model is able to correctly identify the loan status in approximately 76.7% of the cases.\r\n",
    "\r\n",
    "2. **H2O GLM Model:**\r\n",
    "   - **AUC (Area Under the Curve):** 78.39\r\n",
    "   - **Interpretation:** The H2O GLM model, with an AUC of 78.39%, performs slightly better than the standard Logistic Regression model. This suggests that the H2O GLM model has a better discriminative power and is more effective at predicting the loan status.\r\n",
    "\r\n",
    "#### Findings\r\n",
    "\r\n",
    "1. **Model Comparison:**\r\n",
    "   - The H2O GLM model outperforms the Logistic Regression model by a margin of 1.69% in terms of AUC. This indicates that the H2O GLM model is more adept at capturing the nuances in the data that influencer2zation techniques.\r\n",
    "\r\n",
    "3. **Practical Significance:**\r\n",
    "   - In practical terms, a higher AUC translates to better decision-making capabilities. For instance, if these models are used to determine the approval or denial of loan applications, the H2O GLM model will make more accurate decisions, potentially reducing3the Suggestions for improvementaults.\r\n",
    "\r\n",
    "4. **Future Work:**\r\n",
    "   - Given the performance boost from the H2O GLM model, it may be beneficial to explore other machine learning models within the H2O framework, such as H2O GBM (Gradient Boosting Macor other techniques like decision trees and RandomForestshine) or H2O Deep Learning, to see if further i. isions in the financial sector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55eb928-29e9-42ee-b4f1-eaa871df7fa8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
